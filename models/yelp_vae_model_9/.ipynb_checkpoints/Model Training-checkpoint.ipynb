{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "In this notebook, we will train our VAE model. This involves:\n",
    "\n",
    "1. Encoder\n",
    "2. Decoder\n",
    "3. Full Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "We will be using Keras to build and train our VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%matplotlib notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "import h5py\n",
    "\n",
    "# import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer, Add, Multiply, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import model_from_json\n",
    "# import mdn\n",
    "\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from pickle import dump, load\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Constants\n",
    "Hyper parameters and constants will all be located here for ease of adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_dim = 11\n",
    "categorical_map = {0:0, 0.5:1, 1: 2, 1.5:3, 2:4, 2.5:5, 3:6, 3.5:7, 4:8, 4.5:9, 5:10}\n",
    "reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "continuous_dim = 3\n",
    "binary_dim = 1\n",
    "original_dim = binary_dim + continuous_dim + categorical_dim\n",
    "intermediate_dim_1 = 50\n",
    "intermediate_dim_2 = 50\n",
    "latent_dim = 4\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "## Constants for the Mixture layer\n",
    "N_HIDDEN = 15  # number of hidden units in the Dense layer\n",
    "N_MIXES = 10  # number of mixture components\n",
    "OUTPUT_DIMS = 2  # number of real-values predicted by each mixture component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "We have to write our own custom layer and custom loss function as these are not supported on Keras natively. There are a few things to be done:\n",
    "\n",
    "1. Custom KLDivergence Layer\n",
    "2. Custom Loss Functions\n",
    "3. Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence Layer\n",
    "To ensure modularity, we decided to create a separate layer for KL Divergence. This layer will account for the loss required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Functions\n",
    "As the yelp dataset contains binary, categorical as well as continuous data, we will build 3 custom loss functions.\n",
    "\n",
    "#### Binary Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y_true, y_pred):\n",
    "\t# input dimension is (batchsize, 1)\n",
    "    return K.binary_crossentropy(y_true, y_pred) # the dimension of return value is (batchsize , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_loss(y_true, y_pred):\n",
    "\t# input dimension is (batchsize, number of categories)\n",
    "  return K.categorical_crossentropy(y_true, y_pred) # the dimension of return value is (batchsize , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis) # return a tensor of shape (batch_size, 1)\n",
    "\n",
    "# Added a postfix because now we also have poisson as a distribution\n",
    "def continuous_loss_gaussian(y_true, y_pred):\n",
    "\t# need to return log probability for continuous gaussian loss.\n",
    "\t# will get a (batchsize, 6 continuous variable input) where 3 of the 6 represents mu and the others logvar\n",
    "\t# y_true will be (batchsize, 3)\n",
    "  mu, logvar = tf.split(y_pred, num_or_size_splits = 2, axis = 1)\n",
    "  return -1 * log_normal_pdf(y_true, mu, logvar) \n",
    "\n",
    "def continuous_loss_poisson(y_true, y_pred):\n",
    "\t# need to return log probability for continuous poisson loss.\n",
    "\t# will get a (batchsize, 6 continuous variable input) where 3 of the 6 represents mu and the others logvar\n",
    "\t# y_true will be (batchsize, 3)\n",
    "  return tf.nn.log_poisson_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "- tanh/sigmoid is used because Relu resulted in loss going to infinity\n",
    "- going to delete review_log_var and review_mu since we are trying out the Poission distribution which only takes 1 parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tanliangwei/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/tensorflow_core/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "import mdn\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "input_shape = (original_dim,)\n",
    "base_depth = 32\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dim), scale=1), reinterpreted_batch_ndims=1)\n",
    "\n",
    "## Encoder\n",
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=input_shape),\n",
    "    tfkl.Dense(intermediate_dim_1, activation='tanh', name='hidden_enc_1'),\n",
    "    tfkl.Dense(intermediate_dim_2, activation='tanh', name='hidden_enc_2'),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim), activation=None),\n",
    "    tfpl.MultivariateNormalTriL( latent_dim, activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
    "])\n",
    "\n",
    "\n",
    "decode_1 = tfkl.Dense(intermediate_dim_2, activation='tanh', name='hidden_dec_2')\n",
    "h_dec = decode_1(encoder.outputs[0])\n",
    "\n",
    "decode_2 = tfkl.Dense(intermediate_dim_1, activation='tanh', name='hidden_dec_1')\n",
    "h_dec = decode_2(h_dec)\n",
    "\n",
    "x_pred_coordinates_mdn_layer = mdn.MDN(OUTPUT_DIMS, N_MIXES, name = 'x_pred_coordinates_mdn_layer')\n",
    "x_pred_coordinates = x_pred_coordinates_mdn_layer(h_dec)\n",
    "\n",
    "## Old coordinates layer\n",
    "# x_pred_coordinates_mu_layer = tfkl.Dense(2, name='x_pred_coordinates_mu')\n",
    "# x_pred_coordinates_mu = x_pred_coordinates_mu_layer(h_dec)\n",
    "\n",
    "# x_pred_coordinates_log_var_layer = tfkl.Dense(2, name='x_pred_coordinates_log_var')\n",
    "# x_pred_coordinates_log_var = x_pred_coordinates_log_var_layer(h_dec)\n",
    "\n",
    "# x_pred_coordinates_layer = tfkl.Concatenate(axis=-1, name = 'x_pred_coordinates')\n",
    "# x_pred_coordinates = x_pred_coordinates_layer([x_pred_coordinates_mu, x_pred_coordinates_log_var])\n",
    "\n",
    "## This outputs the lambda require for poisson distribution and thats all that we need\n",
    "x_pred_review_log_lambda_layer = tfkl.Dense(1,name = 'x_pred_review_log_lambda_layer')\n",
    "x_pred_review = x_pred_review_log_lambda_layer(h_dec)\n",
    "\n",
    "x_pred_binary_layer = tfkl.Dense(binary_dim, activation='sigmoid', name='x_pred_binary')\n",
    "x_pred_binary = x_pred_binary_layer(h_dec) # binary cross entropy\n",
    "\n",
    "x_pred_categorical_layer = tfkl.Dense(categorical_dim, activation='softmax', name='x_pred_categorical')\n",
    "x_pred_categorical = x_pred_categorical_layer(h_dec) # categorical cross entropy\n",
    "\n",
    "vae = tfk.Model(inputs=encoder.inputs, outputs=[x_pred_binary, x_pred_categorical, x_pred_review, x_pred_coordinates])\n",
    "# vae = tfk.Model(inputs=encoder.inputs,\n",
    "#                 outputs=decoder(encoder.outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Model and Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "vae.compile(optimizer=optimizer, loss=[binary_loss, categorical_loss, continuous_loss_poisson, mdn.get_mixture_loss_func(OUTPUT_DIMS,N_MIXES)], loss_weights=[1, 1, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc_1 (Dense)            (None, 50)           800         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc_2 (Dense)            (None, 50)           2550        hidden_enc_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 14)           714         hidden_enc_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multivariate_normal_tri_l (Mult ((None, 4), (None, 4 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec_2 (Dense)            (None, 50)           250         multivariate_normal_tri_l[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec_1 (Dense)            (None, 50)           2550        hidden_dec_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_binary (Dense)           (None, 1)            51          hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_categorical (Dense)      (None, 11)           561         hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_review_log_lambda_layer  (None, 1)            51          hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_coordinates_mdn_layer (M (None, 50)           2550        hidden_dec_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,077\n",
      "Trainable params: 10,077\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt('../../datasets/yelp_business.csv',delimiter=',',skip_header=1)\n",
    "dataset = dataset[~np.isnan(dataset).any(axis=1)]\n",
    "test_set, train_set = np.split(dataset,[1], axis = 0)\n",
    "\n",
    "def format_data(dataset, scaler_to_use=None ,save_scaler=True):\n",
    "    # handling the categorical variables\n",
    "    coordinates, ratings, reviews, is_opens = np.split(dataset, [2, 3, 4], axis = 1)\n",
    "    one_hot_array = np.zeros((ratings.shape[0], categorical_dim))\n",
    "\n",
    "    for i, r in enumerate(ratings):\n",
    "        one_hot_array[i][categorical_map[r[0]]] = 1\n",
    "    \n",
    "    # handling coordinates\n",
    "    if scaler_to_use is None:\n",
    "        scaler_to_use = preprocessing.StandardScaler()\n",
    "        scaler_to_use.fit(coordinates)\n",
    "    \n",
    "    coordinates = scaler_to_use.transform(coordinates)\n",
    "    \n",
    "    if save_scaler:\n",
    "        dump(scaler_to_use, open('./model/standard_scaler.pkl', 'wb'))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for i, c in enumerate(coordinates):\n",
    "#         coordinates[i][0] = (c[0]+180)/360\n",
    "#         coordinates[i][1] = (c[1]+180)/360\n",
    "\n",
    "    dataset = np.concatenate((coordinates, reviews, is_opens, one_hot_array), axis = 1)\n",
    "\n",
    "    # creating the labels\n",
    "    coordinates_labels = coordinates\n",
    "    review_labels = reviews\n",
    "    categorical_labels = one_hot_array\n",
    "    binary_labels = is_opens\n",
    "    return dataset, coordinates_labels, review_labels, categorical_labels, binary_labels\n",
    "\n",
    "train_dataset, train_coordinates_labels, train_review_labels, train_categorical_labels, train_binary_labels = format_data(train_set)\n",
    "\n",
    "## Open scaler\n",
    "scaler = load(open('./model/standard_scaler.pkl', 'rb'))\n",
    "test_dataset, test_coordinates_labels, test_review_labels, test_categorical_labels, test_binary_labels = format_data(test_set, scaler, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Review_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(train_review_labels, 1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174565 samples, validate on 1 samples\n",
      "Epoch 1/50\n",
      "174565/174565 [==============================] - 23s 130us/sample - loss: -89.7591 - x_pred_binary_loss: 0.6437 - x_pred_categorical_loss: 2.1996 - x_pred_review_log_lambda_layer_loss: -98.8539 - x_pred_coordinates_mdn_layer_loss: 2.0932 - val_loss: -37.2795 - val_x_pred_binary_loss: 0.2235 - val_x_pred_categorical_loss: 1.4427 - val_x_pred_review_log_lambda_layer_loss: -42.5842 - val_x_pred_coordinates_mdn_layer_loss: -0.8998\n",
      "Epoch 2/50\n",
      "174565/174565 [==============================] - 12s 70us/sample - loss: -101.0412 - x_pred_binary_loss: 0.4637 - x_pred_categorical_loss: 2.0334 - x_pred_review_log_lambda_layer_loss: -107.9294 - x_pred_coordinates_mdn_layer_loss: 1.0745 - val_loss: -43.7943 - val_x_pred_binary_loss: 0.1162 - val_x_pred_categorical_loss: 1.5170 - val_x_pred_review_log_lambda_layer_loss: -45.3316 - val_x_pred_coordinates_mdn_layer_loss: -3.4072\n",
      "Epoch 3/50\n",
      "174565/174565 [==============================] - 11s 66us/sample - loss: -102.9163 - x_pred_binary_loss: 0.4425 - x_pred_categorical_loss: 1.9951 - x_pred_review_log_lambda_layer_loss: -108.2175 - x_pred_coordinates_mdn_layer_loss: -0.1535 - val_loss: -42.3126 - val_x_pred_binary_loss: 0.2092 - val_x_pred_categorical_loss: 1.6833 - val_x_pred_review_log_lambda_layer_loss: -42.7606 - val_x_pred_coordinates_mdn_layer_loss: -1.4790\n",
      "Epoch 4/50\n",
      "174565/174565 [==============================] - 13s 74us/sample - loss: -104.2477 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9790 - x_pred_review_log_lambda_layer_loss: -108.2142 - x_pred_coordinates_mdn_layer_loss: -1.2878 - val_loss: -44.3383 - val_x_pred_binary_loss: 0.1875 - val_x_pred_categorical_loss: 1.4400 - val_x_pred_review_log_lambda_layer_loss: -45.8776 - val_x_pred_coordinates_mdn_layer_loss: -2.8473\n",
      "Epoch 5/50\n",
      "174565/174565 [==============================] - 15s 86us/sample - loss: -105.2984 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9725 - x_pred_review_log_lambda_layer_loss: -108.3286 - x_pred_coordinates_mdn_layer_loss: -2.1219 - val_loss: -45.9734 - val_x_pred_binary_loss: 0.1770 - val_x_pred_categorical_loss: 1.6530 - val_x_pred_review_log_lambda_layer_loss: -43.1970 - val_x_pred_coordinates_mdn_layer_loss: -4.4312\n",
      "Epoch 6/50\n",
      "174565/174565 [==============================] - 16s 90us/sample - loss: -105.9572 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9706 - x_pred_review_log_lambda_layer_loss: -108.3658 - x_pred_coordinates_mdn_layer_loss: -2.5940 - val_loss: -46.1113 - val_x_pred_binary_loss: 0.1618 - val_x_pred_categorical_loss: 1.5569 - val_x_pred_review_log_lambda_layer_loss: -45.8666 - val_x_pred_coordinates_mdn_layer_loss: -5.1784\n",
      "Epoch 7/50\n",
      "174565/174565 [==============================] - 14s 81us/sample - loss: -106.3262 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9690 - x_pred_review_log_lambda_layer_loss: -108.3836 - x_pred_coordinates_mdn_layer_loss: -2.8820 - val_loss: -46.6840 - val_x_pred_binary_loss: 0.1684 - val_x_pred_categorical_loss: 1.6679 - val_x_pred_review_log_lambda_layer_loss: -42.7400 - val_x_pred_coordinates_mdn_layer_loss: -5.0290\n",
      "Epoch 8/50\n",
      "174565/174565 [==============================] - 16s 91us/sample - loss: -106.4984 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9684 - x_pred_review_log_lambda_layer_loss: -108.3680 - x_pred_coordinates_mdn_layer_loss: -3.0185 - val_loss: -45.6707 - val_x_pred_binary_loss: 0.1653 - val_x_pred_categorical_loss: 1.5539 - val_x_pred_review_log_lambda_layer_loss: -45.2710 - val_x_pred_coordinates_mdn_layer_loss: -4.7741\n",
      "Epoch 9/50\n",
      "174565/174565 [==============================] - 10s 60us/sample - loss: -106.5062 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9683 - x_pred_review_log_lambda_layer_loss: -108.2789 - x_pred_coordinates_mdn_layer_loss: -3.1023 - val_loss: -46.2116 - val_x_pred_binary_loss: 0.1780 - val_x_pred_categorical_loss: 1.5467 - val_x_pred_review_log_lambda_layer_loss: -45.6449 - val_x_pred_coordinates_mdn_layer_loss: -4.9185\n",
      "Epoch 10/50\n",
      "174565/174565 [==============================] - 13s 75us/sample - loss: -106.6599 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9686 - x_pred_review_log_lambda_layer_loss: -108.3575 - x_pred_coordinates_mdn_layer_loss: -3.1562 - val_loss: -46.5824 - val_x_pred_binary_loss: 0.1611 - val_x_pred_categorical_loss: 1.5244 - val_x_pred_review_log_lambda_layer_loss: -45.9988 - val_x_pred_coordinates_mdn_layer_loss: -5.5398\n",
      "Epoch 11/50\n",
      "174565/174565 [==============================] - 12s 69us/sample - loss: -106.6977 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9683 - x_pred_review_log_lambda_layer_loss: -108.3530 - x_pred_coordinates_mdn_layer_loss: -3.1915 - val_loss: -46.0210 - val_x_pred_binary_loss: 0.1539 - val_x_pred_categorical_loss: 1.3420 - val_x_pred_review_log_lambda_layer_loss: -42.7313 - val_x_pred_coordinates_mdn_layer_loss: -5.0721\n",
      "Epoch 12/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -106.7308 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9680 - x_pred_review_log_lambda_layer_loss: -108.3583 - x_pred_coordinates_mdn_layer_loss: -3.2149 - val_loss: -45.9373 - val_x_pred_binary_loss: 0.1719 - val_x_pred_categorical_loss: 1.5701 - val_x_pred_review_log_lambda_layer_loss: -45.2278 - val_x_pred_coordinates_mdn_layer_loss: -4.7753\n",
      "Epoch 13/50\n",
      "174565/174565 [==============================] - 10s 58us/sample - loss: -106.6940 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.3817 - x_pred_coordinates_mdn_layer_loss: -3.2400 - val_loss: -45.9245 - val_x_pred_binary_loss: 0.1616 - val_x_pred_categorical_loss: 1.4580 - val_x_pred_review_log_lambda_layer_loss: -45.7386 - val_x_pred_coordinates_mdn_layer_loss: -4.8106\n",
      "Epoch 14/50\n",
      "174565/174565 [==============================] - 10s 58us/sample - loss: -106.8219 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9678 - x_pred_review_log_lambda_layer_loss: -108.3845 - x_pred_coordinates_mdn_layer_loss: -3.2667 - val_loss: -45.6956 - val_x_pred_binary_loss: 0.1624 - val_x_pred_categorical_loss: 1.4703 - val_x_pred_review_log_lambda_layer_loss: -45.6191 - val_x_pred_coordinates_mdn_layer_loss: -4.8019\n",
      "Epoch 15/50\n",
      "174565/174565 [==============================] - 10s 58us/sample - loss: -106.8605 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9677 - x_pred_review_log_lambda_layer_loss: -108.4273 - x_pred_coordinates_mdn_layer_loss: -3.2821 - val_loss: -45.9049 - val_x_pred_binary_loss: 0.1661 - val_x_pred_categorical_loss: 1.4414 - val_x_pred_review_log_lambda_layer_loss: -45.4594 - val_x_pred_coordinates_mdn_layer_loss: -4.8120\n",
      "Epoch 16/50\n",
      "174565/174565 [==============================] - 10s 59us/sample - loss: -106.8403 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9677 - x_pred_review_log_lambda_layer_loss: -108.3619 - x_pred_coordinates_mdn_layer_loss: -3.3007 - val_loss: -46.4152 - val_x_pred_binary_loss: 0.1616 - val_x_pred_categorical_loss: 1.5321 - val_x_pred_review_log_lambda_layer_loss: -45.4938 - val_x_pred_coordinates_mdn_layer_loss: -5.2990\n",
      "Epoch 17/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -106.8665 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9677 - x_pred_review_log_lambda_layer_loss: -108.3741 - x_pred_coordinates_mdn_layer_loss: -3.3169 - val_loss: -46.1271 - val_x_pred_binary_loss: 0.1627 - val_x_pred_categorical_loss: 1.5696 - val_x_pred_review_log_lambda_layer_loss: -44.1174 - val_x_pred_coordinates_mdn_layer_loss: -4.7446\n",
      "Epoch 18/50\n",
      "174565/174565 [==============================] - 11s 61us/sample - loss: -106.8861 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.3675 - x_pred_coordinates_mdn_layer_loss: -3.3276 - val_loss: -46.0435 - val_x_pred_binary_loss: 0.1610 - val_x_pred_categorical_loss: 1.4463 - val_x_pred_review_log_lambda_layer_loss: -45.8969 - val_x_pred_coordinates_mdn_layer_loss: -4.9906\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174565/174565 [==============================] - 9s 52us/sample - loss: -106.9605 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9678 - x_pred_review_log_lambda_layer_loss: -108.4358 - x_pred_coordinates_mdn_layer_loss: -3.3386 - val_loss: -46.5223 - val_x_pred_binary_loss: 0.1651 - val_x_pred_categorical_loss: 1.4719 - val_x_pred_review_log_lambda_layer_loss: -45.8426 - val_x_pred_coordinates_mdn_layer_loss: -5.0377\n",
      "Epoch 20/50\n",
      "174565/174565 [==============================] - 10s 55us/sample - loss: -106.9552 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9679 - x_pred_review_log_lambda_layer_loss: -108.4135 - x_pred_coordinates_mdn_layer_loss: -3.3469 - val_loss: -46.1490 - val_x_pred_binary_loss: 0.1545 - val_x_pred_categorical_loss: 1.4142 - val_x_pred_review_log_lambda_layer_loss: -45.5117 - val_x_pred_coordinates_mdn_layer_loss: -5.0186\n",
      "Epoch 21/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -106.8959 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9679 - x_pred_review_log_lambda_layer_loss: -108.3706 - x_pred_coordinates_mdn_layer_loss: -3.3565 - val_loss: -46.5064 - val_x_pred_binary_loss: 0.1651 - val_x_pred_categorical_loss: 1.4861 - val_x_pred_review_log_lambda_layer_loss: -45.7790 - val_x_pred_coordinates_mdn_layer_loss: -5.0612\n",
      "Epoch 22/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -106.9527 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9678 - x_pred_review_log_lambda_layer_loss: -108.4242 - x_pred_coordinates_mdn_layer_loss: -3.3664 - val_loss: -46.0004 - val_x_pred_binary_loss: 0.1595 - val_x_pred_categorical_loss: 1.4939 - val_x_pred_review_log_lambda_layer_loss: -45.8080 - val_x_pred_coordinates_mdn_layer_loss: -4.4940\n",
      "Epoch 23/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -106.9526 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9679 - x_pred_review_log_lambda_layer_loss: -108.3857 - x_pred_coordinates_mdn_layer_loss: -3.3756 - val_loss: -45.8660 - val_x_pred_binary_loss: 0.1595 - val_x_pred_categorical_loss: 1.4342 - val_x_pred_review_log_lambda_layer_loss: -45.4158 - val_x_pred_coordinates_mdn_layer_loss: -4.9716\n",
      "Epoch 24/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -106.9838 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9675 - x_pred_review_log_lambda_layer_loss: -108.3932 - x_pred_coordinates_mdn_layer_loss: -3.3862 - val_loss: -48.1113 - val_x_pred_binary_loss: 0.1844 - val_x_pred_categorical_loss: 1.6419 - val_x_pred_review_log_lambda_layer_loss: -43.0983 - val_x_pred_coordinates_mdn_layer_loss: -4.8156\n",
      "Epoch 25/50\n",
      "174565/174565 [==============================] - 9s 52us/sample - loss: -107.0386 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9675 - x_pred_review_log_lambda_layer_loss: -108.4411 - x_pred_coordinates_mdn_layer_loss: -3.3927 - val_loss: -46.0305 - val_x_pred_binary_loss: 0.1620 - val_x_pred_categorical_loss: 1.4227 - val_x_pred_review_log_lambda_layer_loss: -44.2564 - val_x_pred_coordinates_mdn_layer_loss: -4.9489\n",
      "Epoch 26/50\n",
      "174565/174565 [==============================] - 9s 52us/sample - loss: -107.0236 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.4096 - x_pred_coordinates_mdn_layer_loss: -3.3985 - val_loss: -46.0432 - val_x_pred_binary_loss: 0.1750 - val_x_pred_categorical_loss: 1.5658 - val_x_pred_review_log_lambda_layer_loss: -44.8024 - val_x_pred_coordinates_mdn_layer_loss: -4.9077\n",
      "Epoch 27/50\n",
      "174565/174565 [==============================] - 9s 52us/sample - loss: -107.0750 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9677 - x_pred_review_log_lambda_layer_loss: -108.4421 - x_pred_coordinates_mdn_layer_loss: -3.4041 - val_loss: -46.0030 - val_x_pred_binary_loss: 0.1721 - val_x_pred_categorical_loss: 1.5051 - val_x_pred_review_log_lambda_layer_loss: -45.9082 - val_x_pred_coordinates_mdn_layer_loss: -4.7530\n",
      "Epoch 28/50\n",
      "174565/174565 [==============================] - 9s 53us/sample - loss: -107.0926 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9683 - x_pred_review_log_lambda_layer_loss: -108.4579 - x_pred_coordinates_mdn_layer_loss: -3.4100 - val_loss: -46.6392 - val_x_pred_binary_loss: 0.1691 - val_x_pred_categorical_loss: 1.4287 - val_x_pred_review_log_lambda_layer_loss: -44.9543 - val_x_pred_coordinates_mdn_layer_loss: -4.8998\n",
      "Epoch 29/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -106.9648 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9678 - x_pred_review_log_lambda_layer_loss: -108.3215 - x_pred_coordinates_mdn_layer_loss: -3.4185 - val_loss: -45.6995 - val_x_pred_binary_loss: 0.1695 - val_x_pred_categorical_loss: 1.5613 - val_x_pred_review_log_lambda_layer_loss: -45.3562 - val_x_pred_coordinates_mdn_layer_loss: -4.8362\n",
      "Epoch 30/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -107.1293 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9678 - x_pred_review_log_lambda_layer_loss: -108.5532 - x_pred_coordinates_mdn_layer_loss: -3.4239 - val_loss: -49.2427 - val_x_pred_binary_loss: 0.1846 - val_x_pred_categorical_loss: 1.6879 - val_x_pred_review_log_lambda_layer_loss: -40.5527 - val_x_pred_coordinates_mdn_layer_loss: -4.9627\n",
      "Epoch 31/50\n",
      "174565/174565 [==============================] - 10s 55us/sample - loss: -107.1209 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9683 - x_pred_review_log_lambda_layer_loss: -108.4447 - x_pred_coordinates_mdn_layer_loss: -3.4270 - val_loss: -46.2837 - val_x_pred_binary_loss: 0.1661 - val_x_pred_categorical_loss: 1.4624 - val_x_pred_review_log_lambda_layer_loss: -45.6937 - val_x_pred_coordinates_mdn_layer_loss: -4.9358\n",
      "Epoch 32/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -107.1278 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9680 - x_pred_review_log_lambda_layer_loss: -108.4580 - x_pred_coordinates_mdn_layer_loss: -3.4308 - val_loss: -46.2630 - val_x_pred_binary_loss: 0.1686 - val_x_pred_categorical_loss: 1.5489 - val_x_pred_review_log_lambda_layer_loss: -45.3654 - val_x_pred_coordinates_mdn_layer_loss: -4.9854\n",
      "Epoch 33/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -107.1173 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9678 - x_pred_review_log_lambda_layer_loss: -108.4303 - x_pred_coordinates_mdn_layer_loss: -3.4342 - val_loss: -46.0482 - val_x_pred_binary_loss: 0.1751 - val_x_pred_categorical_loss: 1.5469 - val_x_pred_review_log_lambda_layer_loss: -45.8088 - val_x_pred_coordinates_mdn_layer_loss: -4.9603\n",
      "Epoch 34/50\n",
      "174565/174565 [==============================] - 9s 53us/sample - loss: -107.0071 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9680 - x_pred_review_log_lambda_layer_loss: -108.3276 - x_pred_coordinates_mdn_layer_loss: -3.4387 - val_loss: -45.8451 - val_x_pred_binary_loss: 0.1720 - val_x_pred_categorical_loss: 1.5569 - val_x_pred_review_log_lambda_layer_loss: -45.3598 - val_x_pred_coordinates_mdn_layer_loss: -4.9163\n",
      "Epoch 35/50\n",
      "174565/174565 [==============================] - 10s 56us/sample - loss: -107.1954 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9680 - x_pred_review_log_lambda_layer_loss: -108.4915 - x_pred_coordinates_mdn_layer_loss: -3.4459 - val_loss: -45.7618 - val_x_pred_binary_loss: 0.1790 - val_x_pred_categorical_loss: 1.6144 - val_x_pred_review_log_lambda_layer_loss: -44.4669 - val_x_pred_coordinates_mdn_layer_loss: -4.8268\n",
      "Epoch 36/50\n",
      "174565/174565 [==============================] - 11s 64us/sample - loss: -107.1709 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9674 - x_pred_review_log_lambda_layer_loss: -108.4681 - x_pred_coordinates_mdn_layer_loss: -3.4488 - val_loss: -44.8168 - val_x_pred_binary_loss: 0.1847 - val_x_pred_categorical_loss: 1.5627 - val_x_pred_review_log_lambda_layer_loss: -44.6074 - val_x_pred_coordinates_mdn_layer_loss: -4.5235\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174565/174565 [==============================] - 10s 58us/sample - loss: -107.1658 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9677 - x_pred_review_log_lambda_layer_loss: -108.4705 - x_pred_coordinates_mdn_layer_loss: -3.4493 - val_loss: -45.3601 - val_x_pred_binary_loss: 0.1821 - val_x_pred_categorical_loss: 1.5728 - val_x_pred_review_log_lambda_layer_loss: -44.9149 - val_x_pred_coordinates_mdn_layer_loss: -4.7421\n",
      "Epoch 38/50\n",
      "174565/174565 [==============================] - 10s 56us/sample - loss: -107.1673 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9676 - x_pred_review_log_lambda_layer_loss: -108.4496 - x_pred_coordinates_mdn_layer_loss: -3.4523 - val_loss: -46.6886 - val_x_pred_binary_loss: 0.1687 - val_x_pred_categorical_loss: 1.6885 - val_x_pred_review_log_lambda_layer_loss: -41.7439 - val_x_pred_coordinates_mdn_layer_loss: -4.9141\n",
      "Epoch 39/50\n",
      "174565/174565 [==============================] - 10s 60us/sample - loss: -107.1467 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9673 - x_pred_review_log_lambda_layer_loss: -108.4284 - x_pred_coordinates_mdn_layer_loss: -3.4558 - val_loss: -45.8594 - val_x_pred_binary_loss: 0.1726 - val_x_pred_categorical_loss: 1.5212 - val_x_pred_review_log_lambda_layer_loss: -46.0029 - val_x_pred_coordinates_mdn_layer_loss: -4.9028\n",
      "Epoch 40/50\n",
      "174565/174565 [==============================] - 11s 64us/sample - loss: -107.1829 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9676 - x_pred_review_log_lambda_layer_loss: -108.4508 - x_pred_coordinates_mdn_layer_loss: -3.4584 - val_loss: -45.7019 - val_x_pred_binary_loss: 0.1702 - val_x_pred_categorical_loss: 1.5307 - val_x_pred_review_log_lambda_layer_loss: -45.8794 - val_x_pred_coordinates_mdn_layer_loss: -4.6760\n",
      "Epoch 41/50\n",
      "174565/174565 [==============================] - 15s 84us/sample - loss: -107.1794 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9677 - x_pred_review_log_lambda_layer_loss: -108.4580 - x_pred_coordinates_mdn_layer_loss: -3.4643 - val_loss: -46.0683 - val_x_pred_binary_loss: 0.1701 - val_x_pred_categorical_loss: 1.5156 - val_x_pred_review_log_lambda_layer_loss: -46.0012 - val_x_pred_coordinates_mdn_layer_loss: -4.8376\n",
      "Epoch 42/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -107.2040 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9672 - x_pred_review_log_lambda_layer_loss: -108.5696 - x_pred_coordinates_mdn_layer_loss: -3.4623 - val_loss: -45.6000 - val_x_pred_binary_loss: 0.1731 - val_x_pred_categorical_loss: 1.5786 - val_x_pred_review_log_lambda_layer_loss: -45.0635 - val_x_pred_coordinates_mdn_layer_loss: -4.8169\n",
      "Epoch 43/50\n",
      "174565/174565 [==============================] - 13s 73us/sample - loss: -107.1225 - x_pred_binary_loss: 0.4380 - x_pred_categorical_loss: 1.9675 - x_pred_review_log_lambda_layer_loss: -108.3718 - x_pred_coordinates_mdn_layer_loss: -3.4663 - val_loss: -46.0594 - val_x_pred_binary_loss: 0.1817 - val_x_pred_categorical_loss: 1.5656 - val_x_pred_review_log_lambda_layer_loss: -45.4349 - val_x_pred_coordinates_mdn_layer_loss: -4.9959\n",
      "Epoch 44/50\n",
      "174565/174565 [==============================] - 25s 144us/sample - loss: -107.1942 - x_pred_binary_loss: 0.4380 - x_pred_categorical_loss: 1.9673 - x_pred_review_log_lambda_layer_loss: -108.4579 - x_pred_coordinates_mdn_layer_loss: -3.4700 - val_loss: -45.6684 - val_x_pred_binary_loss: 0.1788 - val_x_pred_categorical_loss: 1.5278 - val_x_pred_review_log_lambda_layer_loss: -45.9054 - val_x_pred_coordinates_mdn_layer_loss: -4.6709\n",
      "Epoch 45/50\n",
      "174565/174565 [==============================] - 17s 96us/sample - loss: -107.2824 - x_pred_binary_loss: 0.4380 - x_pred_categorical_loss: 1.9673 - x_pred_review_log_lambda_layer_loss: -108.5184 - x_pred_coordinates_mdn_layer_loss: -3.4740 - val_loss: -46.1584 - val_x_pred_binary_loss: 0.1635 - val_x_pred_categorical_loss: 1.4569 - val_x_pred_review_log_lambda_layer_loss: -45.5441 - val_x_pred_coordinates_mdn_layer_loss: -4.8683\n",
      "Epoch 46/50\n",
      "174565/174565 [==============================] - 29s 167us/sample - loss: -107.2247 - x_pred_binary_loss: 0.4379 - x_pred_categorical_loss: 1.9674 - x_pred_review_log_lambda_layer_loss: -108.4678 - x_pred_coordinates_mdn_layer_loss: -3.4692 - val_loss: -46.6944 - val_x_pred_binary_loss: 0.1733 - val_x_pred_categorical_loss: 1.4801 - val_x_pred_review_log_lambda_layer_loss: -45.9112 - val_x_pred_coordinates_mdn_layer_loss: -4.9440\n",
      "Epoch 47/50\n",
      "174565/174565 [==============================] - 20s 113us/sample - loss: -107.2040 - x_pred_binary_loss: 0.4380 - x_pred_categorical_loss: 1.9671 - x_pred_review_log_lambda_layer_loss: -108.4226 - x_pred_coordinates_mdn_layer_loss: -3.4737 - val_loss: -46.9034 - val_x_pred_binary_loss: 0.1744 - val_x_pred_categorical_loss: 1.7076 - val_x_pred_review_log_lambda_layer_loss: -40.8735 - val_x_pred_coordinates_mdn_layer_loss: -5.1651\n",
      "Epoch 48/50\n",
      "174565/174565 [==============================] - 13s 75us/sample - loss: -107.2548 - x_pred_binary_loss: 0.4379 - x_pred_categorical_loss: 1.9673 - x_pred_review_log_lambda_layer_loss: -108.4836 - x_pred_coordinates_mdn_layer_loss: -3.4782 - val_loss: -45.4822 - val_x_pred_binary_loss: 0.1788 - val_x_pred_categorical_loss: 1.5571 - val_x_pred_review_log_lambda_layer_loss: -45.3158 - val_x_pred_coordinates_mdn_layer_loss: -4.8320\n",
      "Epoch 49/50\n",
      "174565/174565 [==============================] - 10s 59us/sample - loss: -107.2376 - x_pred_binary_loss: 0.4379 - x_pred_categorical_loss: 1.9671 - x_pred_review_log_lambda_layer_loss: -108.4614 - x_pred_coordinates_mdn_layer_loss: -3.4802 - val_loss: -46.0467 - val_x_pred_binary_loss: 0.1583 - val_x_pred_categorical_loss: 1.4014 - val_x_pred_review_log_lambda_layer_loss: -43.0799 - val_x_pred_coordinates_mdn_layer_loss: -5.1327\n",
      "Epoch 50/50\n",
      "174565/174565 [==============================] - 12s 67us/sample - loss: -107.3076 - x_pred_binary_loss: 0.4379 - x_pred_categorical_loss: 1.9670 - x_pred_review_log_lambda_layer_loss: -108.5288 - x_pred_coordinates_mdn_layer_loss: -3.4793 - val_loss: -46.2139 - val_x_pred_binary_loss: 0.1661 - val_x_pred_categorical_loss: 1.4589 - val_x_pred_review_log_lambda_layer_loss: -45.7886 - val_x_pred_coordinates_mdn_layer_loss: -4.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f04f748>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(train_dataset , [train_binary_labels, train_categorical_labels, train_review_labels, train_coordinates_labels], shuffle = True, epochs = epochs, batch_size = batch_size, validation_data=(test_dataset , [test_binary_labels, test_categorical_labels, test_review_labels, test_coordinates_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_input = Input(shape=(latent_dim, ), name = 'decode_input')\n",
    "decode_layer_1 = decode_1(decode_input)\n",
    "decode_layer_2 = decode_2(decode_layer_1)\n",
    "\n",
    "decode_x_pred_coordinates=x_pred_coordinates_mdn_layer(decode_layer_2)\n",
    "# x_pred_coordinates_mu = x_pred_coordinates_mu_layer(decode_layer_2)\n",
    "# x_pred_coordinates_log_var = x_pred_coordinates_log_var_layer(decode_layer_2)\n",
    "# decode_x_pred_coordinates = x_pred_coordinates_layer([x_pred_coordinates_mu, x_pred_coordinates_log_var])\n",
    "\n",
    "decode_x_pred_review = x_pred_review_log_lambda_layer(decode_layer_2)\n",
    "\n",
    "decode_x_pred_binary = x_pred_binary_layer(decode_layer_2) # binary cross entropy\n",
    "decode_x_pred_categorical = x_pred_categorical_layer(decode_layer_2) # categorical cross entropy\n",
    "\n",
    "\n",
    "decoder = Model(decode_input, [decode_x_pred_coordinates, decode_x_pred_review, decode_x_pred_categorical, decode_x_pred_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'InputLayer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8ad28151f4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m SVG(model_to_dot(decoder, show_shapes=True)\n\u001b[0m\u001b[1;32m      2\u001b[0m     .create(prog='dot', format='svg'))\n",
      "\u001b[0;32m~/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mnode_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ib-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minbound_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0minbound_layer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'InputLayer' object is not iterable"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(decoder, show_shapes=True)\n",
    "    .create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Models and Metadata\n",
    "#### Saving Models (Actually, only the decoder matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = vae.to_json()\n",
    "with open(\"./model/vae_full_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "vae.save_weights(\"./model/vae_full_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# encoder = Model(x, [z_mu, z_log_var])\n",
    "model_json = encoder.to_json()\n",
    "with open(\"./model/vae_encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "encoder.save_weights(\"./model/vae_encoder.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model_json = decoder.to_json()\n",
    "with open(\"./model/vae_decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "decoder.save_weights(\"./model/vae_decoder.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating and Saving Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "vae_sample = train_dataset[np.random.choice(len(train_dataset), size=10000, replace=False)]\n",
    "test = encoder.predict(vae_sample, batch_size=batch_size)\n",
    "predictions = decoder.predict(test, batch_size = None, steps = 1)\n",
    "vae_samples = reconstruct(predictions)\n",
    "file_name = './samples/vae_8_sample_' + str(len(vae_samples)) + '.csv'\n",
    "np.savetxt(file_name, vae_samples, delimiter = ',', header='latitude,longitude,stars,review_count,is_open')\n",
    "# np.save('./model/sample_mu.npy', vae_sample_mu)\n",
    "# np.save('./model/sample_log_var.npy', vae_sample_log_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating some Samples for Testing\n",
    "#### Functions for data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "def sample(model, input_mu, input_log_var, samples_per_z=1):\n",
    "    multiplied_input_mu = np.repeat(input_mu, samples_per_z, axis=0)\n",
    "    multiplied_input_log_var = np.repeat(input_log_var, samples_per_z, axis=0)\n",
    "    eps = np.random.normal(size=(multiplied_input_mu.shape[0], latent_dim))\n",
    "    z = reparameterize(multiplied_input_mu, multiplied_input_log_var, eps)\n",
    "    predictions = model.predict(z, batch_size = None, steps = 1)\n",
    "    return reconstruct(predictions)\n",
    "    \n",
    "def reconstruct(predictions):\n",
    "    coordinates, review, categorical, binary = predictions\n",
    "    \n",
    "    # coordinates handled here\n",
    "    print(coordinates.shape)\n",
    "    coordinates_data = np.apply_along_axis(mdn.sample_from_output, 1, coordinates, OUTPUT_DIMS, N_MIXES, temp=1.0)\n",
    "    coordinates_data = np.squeeze(coordinates_data, axis=1)\n",
    "#     mu, log_var = np.split(coordinates, indices_or_sections = 2,axis = 1)\n",
    "#     eps = np.random.normal(size=mu.shape)\n",
    "#     coordinates_data = reparameterize(mu, log_var, eps)\n",
    "    scaler = load(open('./model/standard_scaler.pkl', 'rb'))\n",
    "    coordinates_data = scaler.inverse_transform(coordinates_data)\n",
    "    print(coordinates_data.shape)\n",
    "    \n",
    "    for i, c in enumerate(coordinates_data):\n",
    "        if c[0] > 180.0:\n",
    "            coordinates_data[i][0]= 180.0\n",
    "        if c[0] < -180.0:\n",
    "            coordinates_data[i][0]= -180.0\n",
    "        if c[1] > 180.0:\n",
    "            coordinates_data[i][1]= 180.0\n",
    "        if c[1] < -180.0:\n",
    "            coordinates_data[i][1]= -180.0\n",
    "    \n",
    "    ## review_count handled here\n",
    "    exp_log_review = np.exp(review)\n",
    "    review_data = np.random.poisson(lam=exp_log_review, size = review.shape)\n",
    "    for i, r in enumerate(review_data):\n",
    "        if r[0] < 0:\n",
    "            review_data[i][0] = 0\n",
    "        review_data[i][0] = float(int(review_data[i][0]))\n",
    "    \n",
    "    categorical = np.apply_along_axis(lambda t : np.random.multinomial(1,t), -1, categorical)\n",
    "    categorical = np.apply_along_axis(lambda t : np.argmax(t), -1, categorical)\n",
    "    categorical = np.expand_dims(categorical, axis = -1)\n",
    "    categorical_data = np.apply_along_axis(lambda t : float(reverse_categorical_map[t[0]]), -1, categorical)\n",
    "    categorical_data = np.expand_dims(categorical_data, axis = -1)\n",
    "    binary_data = np.apply_along_axis(lambda t: np.random.binomial(1, t), -1, binary)\n",
    "#     coordinates, reviews = np.split(continuous_data, indices_or_sections=[2], axis = 1)\n",
    "    return np.concatenate([coordinates_data, categorical_data, review_data, binary_data], axis = 1)\n",
    "    \n",
    "\n",
    "def reparameterize(input_mu, input_log_var, eps):\n",
    "    sigma = np.exp(0.5*input_log_var)\n",
    "    return eps*sigma + input_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Samples\n",
    "Make use of the funciton sample to generate samples with our model. U need to supply an array of mu and their respective log var in a separate array to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "vae_samples = sample(decoder, vae_sample_mu, vae_sample_log_var)\n",
    "\n",
    "# Saving the samples in a separate file\n",
    "file_name = './samples/vae_8_sample_' + str(len(vae_samples)) + '.csv'\n",
    "np.savetxt(file_name, vae_samples, delimiter = ',', header='latitude,longitude,stars,review_count,is_open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  36.12722656, -114.97610985,    1.        ,    0.        ,\n",
       "           1.        ],\n",
       "       [  43.64995768,  -79.71934736,    4.        ,    2.        ,\n",
       "           1.        ],\n",
       "       [  41.24716502,  -82.14576402,    3.        ,    3.        ,\n",
       "           1.        ],\n",
       "       [  38.83486706,  -81.44808577,    1.        ,    1.        ,\n",
       "           1.        ],\n",
       "       [  33.52494004, -112.20338825,    5.        ,    6.        ,\n",
       "           1.        ],\n",
       "       [  43.83154703,  -79.53044245,    3.        ,    4.        ,\n",
       "           1.        ],\n",
       "       [  33.47541187, -111.71694681,    5.        ,    3.        ,\n",
       "           1.        ],\n",
       "       [  43.03446893,  -80.8353163 ,    1.5       ,    3.        ,\n",
       "           1.        ],\n",
       "       [  45.55855775,  -73.54997901,    2.        ,    7.        ,\n",
       "           1.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_samples[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
