{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "In this notebook, we will train our VAE model. This involves:\n",
    "\n",
    "1. Encoder\n",
    "2. Decoder\n",
    "3. Full Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "We will be using Keras to build and train our VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%matplotlib notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "import h5py\n",
    "\n",
    "# import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer, Add, Multiply, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import model_from_json\n",
    "# import mdn\n",
    "\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from pickle import dump, load\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Constants\n",
    "Hyper parameters and constants will all be located here for ease of adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_dim = 11\n",
    "categorical_map = {0:0, 0.5:1, 1: 2, 1.5:3, 2:4, 2.5:5, 3:6, 3.5:7, 4:8, 4.5:9, 5:10}\n",
    "reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "continuous_dim = 3\n",
    "binary_dim = 1\n",
    "original_dim = binary_dim + continuous_dim + categorical_dim\n",
    "intermediate_dim_1 = 50\n",
    "intermediate_dim_2 = 50\n",
    "latent_dim = 4\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "## Constants for the Mixture layer\n",
    "N_HIDDEN = 15  # number of hidden units in the Dense layer\n",
    "N_MIXES = 10  # number of mixture components\n",
    "OUTPUT_DIMS = 2  # number of real-values predicted by each mixture component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "We have to write our own custom layer and custom loss function as these are not supported on Keras natively. There are a few things to be done:\n",
    "\n",
    "1. Custom KLDivergence Layer\n",
    "2. Custom Loss Functions\n",
    "3. Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence Layer\n",
    "To ensure modularity, we decided to create a separate layer for KL Divergence. This layer will account for the loss required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Functions\n",
    "As the yelp dataset contains binary, categorical as well as continuous data, we will build 3 custom loss functions.\n",
    "\n",
    "#### Binary Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y_true, y_pred):\n",
    "\t# input dimension is (batchsize, 1)\n",
    "    return K.binary_crossentropy(y_true, y_pred) # the dimension of return value is (batchsize , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_loss(y_true, y_pred):\n",
    "\t# input dimension is (batchsize, number of categories)\n",
    "  return K.categorical_crossentropy(y_true, y_pred) # the dimension of return value is (batchsize , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis) # return a tensor of shape (batch_size, 1)\n",
    "\n",
    "# Added a postfix because now we also have poisson as a distribution\n",
    "def continuous_loss_gaussian(y_true, y_pred):\n",
    "\t# need to return log probability for continuous gaussian loss.\n",
    "\t# will get a (batchsize, 6 continuous variable input) where 3 of the 6 represents mu and the others logvar\n",
    "\t# y_true will be (batchsize, 3)\n",
    "  mu, logvar = tf.split(y_pred, num_or_size_splits = 2, axis = 1)\n",
    "  return -1 * log_normal_pdf(y_true, mu, logvar) \n",
    "\n",
    "def continuous_loss_poisson(y_true, y_pred):\n",
    "\t# need to return log probability for continuous poisson loss.\n",
    "\t# will get a (batchsize, 6 continuous variable input) where 3 of the 6 represents mu and the others logvar\n",
    "\t# y_true will be (batchsize, 3)\n",
    "  return tf.nn.log_poisson_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "- tanh/sigmoid is used because Relu resulted in loss going to infinity\n",
    "- going to delete review_log_var and review_mu since we are trying out the Poission distribution which only takes 1 parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tanliangwei/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/tensorflow_core/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "import mdn\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "input_shape = (original_dim,)\n",
    "base_depth = 32\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dim), scale=1), reinterpreted_batch_ndims=1)\n",
    "\n",
    "## Encoder\n",
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=input_shape),\n",
    "    tfkl.Dense(intermediate_dim_1, activation='tanh', name='hidden_enc_1'),\n",
    "    tfkl.Dense(intermediate_dim_2, activation='tanh', name='hidden_enc_2'),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim), activation=None),\n",
    "    tfpl.MultivariateNormalTriL( latent_dim, activity_regularizer=tfpl.KLDivergenceRegularizer(prior ,weight = 1.0)),\n",
    "])\n",
    "\n",
    "\n",
    "decode_1 = tfkl.Dense(intermediate_dim_2, activation='tanh', name='hidden_dec_2')\n",
    "h_dec = decode_1(encoder.outputs[0])\n",
    "\n",
    "decode_2 = tfkl.Dense(intermediate_dim_1, activation='tanh', name='hidden_dec_1')\n",
    "h_dec = decode_2(h_dec)\n",
    "\n",
    "# x_pred_coordinates_mdn_layer = mdn.MDN(OUTPUT_DIMS, N_MIXES, name = 'x_pred_coordinates_mdn_layer')\n",
    "# x_pred_coordinates = x_pred_coordinates_mdn_layer(h_dec)\n",
    "\n",
    "## Old coordinates layer\n",
    "x_pred_coordinates_mu_layer = tfkl.Dense(2, name='x_pred_coordinates_mu')\n",
    "x_pred_coordinates_mu = x_pred_coordinates_mu_layer(h_dec)\n",
    "\n",
    "x_pred_coordinates_log_var_layer = tfkl.Dense(2, name='x_pred_coordinates_log_var')\n",
    "x_pred_coordinates_log_var = x_pred_coordinates_log_var_layer(h_dec)\n",
    "\n",
    "x_pred_coordinates_layer = tfkl.Concatenate(axis=-1, name = 'x_pred_coordinates')\n",
    "x_pred_coordinates = x_pred_coordinates_layer([x_pred_coordinates_mu, x_pred_coordinates_log_var])\n",
    "\n",
    "## This outputs the lambda require for poisson distribution and thats all that we need\n",
    "x_pred_review_log_lambda_layer = tfkl.Dense(1,name = 'x_pred_review_log_lambda_layer')\n",
    "x_pred_review = x_pred_review_log_lambda_layer(h_dec)\n",
    "\n",
    "x_pred_binary_layer = tfkl.Dense(binary_dim, activation='sigmoid', name='x_pred_binary')\n",
    "x_pred_binary = x_pred_binary_layer(h_dec) # binary cross entropy\n",
    "\n",
    "x_pred_categorical_layer = tfkl.Dense(categorical_dim, activation='softmax', name='x_pred_categorical')\n",
    "x_pred_categorical = x_pred_categorical_layer(h_dec) # categorical cross entropy\n",
    "\n",
    "vae = tfk.Model(inputs=encoder.inputs, outputs=[x_pred_binary, x_pred_categorical, x_pred_review, x_pred_coordinates])\n",
    "# vae = tfk.Model(inputs=encoder.inputs,\n",
    "#                 outputs=decoder(encoder.outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Model and Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "vae.compile(optimizer=optimizer, loss=[binary_loss, categorical_loss, continuous_loss_poisson, continuous_loss_gaussian], loss_weights=[1, 1, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc_1 (Dense)            (None, 50)           800         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc_2 (Dense)            (None, 50)           2550        hidden_enc_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 14)           714         hidden_enc_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multivariate_normal_tri_l (Mult ((None, 4), (None, 4 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec_2 (Dense)            (None, 50)           250         multivariate_normal_tri_l[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec_1 (Dense)            (None, 50)           2550        hidden_dec_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_coordinates_mu (Dense)   (None, 2)            102         hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_coordinates_log_var (Den (None, 2)            102         hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_binary (Dense)           (None, 1)            51          hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_categorical (Dense)      (None, 11)           561         hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_review_log_lambda_layer  (None, 1)            51          hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_coordinates (Concatenate (None, 4)            0           x_pred_coordinates_mu[0][0]      \n",
      "                                                                 x_pred_coordinates_log_var[0][0] \n",
      "==================================================================================================\n",
      "Total params: 7,731\n",
      "Trainable params: 7,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt('../../datasets/yelp_business.csv',delimiter=',',skip_header=1)\n",
    "dataset = dataset[~np.isnan(dataset).any(axis=1)]\n",
    "test_set, train_set = np.split(dataset,[1], axis = 0)\n",
    "\n",
    "def format_data(dataset, scaler_to_use=None ,save_scaler=True):\n",
    "    # handling the categorical variables\n",
    "    coordinates, ratings, reviews, is_opens = np.split(dataset, [2, 3, 4], axis = 1)\n",
    "    one_hot_array = np.zeros((ratings.shape[0], categorical_dim))\n",
    "\n",
    "    for i, r in enumerate(ratings):\n",
    "        one_hot_array[i][categorical_map[r[0]]] = 1\n",
    "    \n",
    "    # handling coordinates\n",
    "    if scaler_to_use is None:\n",
    "        scaler_to_use = preprocessing.StandardScaler()\n",
    "        scaler_to_use.fit(coordinates)\n",
    "    \n",
    "    coordinates = scaler_to_use.transform(coordinates)\n",
    "    \n",
    "    if save_scaler:\n",
    "        dump(scaler_to_use, open('./model/standard_scaler.pkl', 'wb'))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for i, c in enumerate(coordinates):\n",
    "#         coordinates[i][0] = (c[0]+180)/360\n",
    "#         coordinates[i][1] = (c[1]+180)/360\n",
    "\n",
    "    dataset = np.concatenate((coordinates, reviews, is_opens, one_hot_array), axis = 1)\n",
    "\n",
    "    # creating the labels\n",
    "    coordinates_labels = coordinates\n",
    "    review_labels = reviews\n",
    "    categorical_labels = one_hot_array\n",
    "    binary_labels = is_opens\n",
    "    return dataset, coordinates_labels, review_labels, categorical_labels, binary_labels\n",
    "\n",
    "train_dataset, train_coordinates_labels, train_review_labels, train_categorical_labels, train_binary_labels = format_data(train_set)\n",
    "\n",
    "## Open scaler\n",
    "scaler = load(open('./model/standard_scaler.pkl', 'rb'))\n",
    "test_dataset, test_coordinates_labels, test_review_labels, test_categorical_labels, test_binary_labels = format_data(test_set, scaler, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Review_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(train_review_labels, 1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174565 samples, validate on 1 samples\n",
      "Epoch 1/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -89.3908 - x_pred_binary_loss: 0.5575 - x_pred_categorical_loss: 2.1487 - x_pred_review_log_lambda_layer_loss: -98.9316 - x_pred_coordinates_loss: 2.8615 - val_loss: -36.2812 - val_x_pred_binary_loss: 0.2023 - val_x_pred_categorical_loss: 1.5566 - val_x_pred_review_log_lambda_layer_loss: -45.7173 - val_x_pred_coordinates_loss: 2.1377\n",
      "Epoch 2/50\n",
      "174565/174565 [==============================] - 7s 40us/sample - loss: -99.1855 - x_pred_binary_loss: 0.4692 - x_pred_categorical_loss: 2.0245 - x_pred_review_log_lambda_layer_loss: -107.8138 - x_pred_coordinates_loss: 2.6943 - val_loss: -37.4805 - val_x_pred_binary_loss: 0.1189 - val_x_pred_categorical_loss: 1.4510 - val_x_pred_review_log_lambda_layer_loss: -45.9229 - val_x_pred_coordinates_loss: 1.7828\n",
      "Epoch 3/50\n",
      "174565/174565 [==============================] - 8s 45us/sample - loss: -99.9121 - x_pred_binary_loss: 0.4540 - x_pred_categorical_loss: 1.9930 - x_pred_review_log_lambda_layer_loss: -108.1017 - x_pred_coordinates_loss: 2.6221 - val_loss: -37.7754 - val_x_pred_binary_loss: 0.1759 - val_x_pred_categorical_loss: 1.5140 - val_x_pred_review_log_lambda_layer_loss: -45.1419 - val_x_pred_coordinates_loss: 1.8315\n",
      "Epoch 4/50\n",
      "174565/174565 [==============================] - 6s 35us/sample - loss: -100.4129 - x_pred_binary_loss: 0.4429 - x_pred_categorical_loss: 1.9758 - x_pred_review_log_lambda_layer_loss: -108.2374 - x_pred_coordinates_loss: 2.5579 - val_loss: -38.7134 - val_x_pred_binary_loss: 0.1674 - val_x_pred_categorical_loss: 1.5701 - val_x_pred_review_log_lambda_layer_loss: -43.9044 - val_x_pred_coordinates_loss: 2.3253\n",
      "Epoch 5/50\n",
      "174565/174565 [==============================] - 6s 36us/sample - loss: -100.6544 - x_pred_binary_loss: 0.4391 - x_pred_categorical_loss: 1.9673 - x_pred_review_log_lambda_layer_loss: -108.2849 - x_pred_coordinates_loss: 2.4666 - val_loss: -38.6958 - val_x_pred_binary_loss: 0.1657 - val_x_pred_categorical_loss: 1.5673 - val_x_pred_review_log_lambda_layer_loss: -45.4320 - val_x_pred_coordinates_loss: 2.0916185 - x_pred_\n",
      "Epoch 6/50\n",
      "174565/174565 [==============================] - 6s 35us/sample - loss: -100.7552 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9632 - x_pred_review_log_lambda_layer_loss: -108.2954 - x_pred_coordinates_loss: 2.3813 - val_loss: -38.1999 - val_x_pred_binary_loss: 0.1479 - val_x_pred_categorical_loss: 1.4318 - val_x_pred_review_log_lambda_layer_loss: -44.5035 - val_x_pred_coordinates_loss: 1.9395\n",
      "Epoch 7/50\n",
      "174565/174565 [==============================] - 7s 39us/sample - loss: -100.8213 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9597 - x_pred_review_log_lambda_layer_loss: -108.3328 - x_pred_coordinates_loss: 2.3180 - val_loss: -38.4069 - val_x_pred_binary_loss: 0.1629 - val_x_pred_categorical_loss: 1.6990 - val_x_pred_review_log_lambda_layer_loss: -44.5432 - val_x_pred_coordinates_loss: 0.6752og_lambda_layer_loss: -108.0880\n",
      "Epoch 8/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -100.9126 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9581 - x_pred_review_log_lambda_layer_loss: -108.3859 - x_pred_coordinates_loss: 2.2549 - val_loss: -38.8288 - val_x_pred_binary_loss: 0.1623 - val_x_pred_categorical_loss: 1.5278 - val_x_pred_review_log_lambda_layer_loss: -45.1982 - val_x_pred_coordinates_loss: 2.7272\n",
      "Epoch 9/50\n",
      "174565/174565 [==============================] - 12s 66us/sample - loss: -100.8903 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9565 - x_pred_review_log_lambda_layer_loss: -108.3463 - x_pred_coordinates_loss: 2.2140 - val_loss: -39.5819 - val_x_pred_binary_loss: 0.1864 - val_x_pred_categorical_loss: 1.6312 - val_x_pred_review_log_lambda_layer_loss: -45.4875 - val_x_pred_coordinates_loss: 0.1537\n",
      "Epoch 10/50\n",
      "174565/174565 [==============================] - 8s 46us/sample - loss: -100.9167 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9549 - x_pred_review_log_lambda_layer_loss: -108.3681 - x_pred_coordinates_loss: 2.1702 - val_loss: -39.0976 - val_x_pred_binary_loss: 0.1569 - val_x_pred_categorical_loss: 1.4432 - val_x_pred_review_log_lambda_layer_loss: -44.7891 - val_x_pred_coordinates_loss: 1.9538\n",
      "Epoch 11/50\n",
      "174565/174565 [==============================] - 6s 34us/sample - loss: -100.9789 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9540 - x_pred_review_log_lambda_layer_loss: -108.3976 - x_pred_coordinates_loss: 2.1348 - val_loss: -39.0619 - val_x_pred_binary_loss: 0.1591 - val_x_pred_categorical_loss: 1.5236 - val_x_pred_review_log_lambda_layer_loss: -45.6631 - val_x_pred_coordinates_loss: 2.2233\n",
      "Epoch 12/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -100.9990 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9525 - x_pred_review_log_lambda_layer_loss: -108.4046 - x_pred_coordinates_loss: 2.0798 - val_loss: -39.7700 - val_x_pred_binary_loss: 0.1810 - val_x_pred_categorical_loss: 1.7480 - val_x_pred_review_log_lambda_layer_loss: -45.8444 - val_x_pred_coordinates_loss: -0.2990\n",
      "Epoch 13/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -100.9110 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9515 - x_pred_review_log_lambda_layer_loss: -108.3167 - x_pred_coordinates_loss: 2.0390 - val_loss: -39.7233 - val_x_pred_binary_loss: 0.1674 - val_x_pred_categorical_loss: 1.6033 - val_x_pred_review_log_lambda_layer_loss: -45.7586 - val_x_pred_coordinates_loss: 0.1404\n",
      "Epoch 14/50\n",
      "174565/174565 [==============================] - 6s 33us/sample - loss: -101.0135 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9504 - x_pred_review_log_lambda_layer_loss: -108.4029 - x_pred_coordinates_loss: 2.0045 - val_loss: -39.4112 - val_x_pred_binary_loss: 0.1583 - val_x_pred_categorical_loss: 1.4963 - val_x_pred_review_log_lambda_layer_loss: -45.9988 - val_x_pred_coordinates_loss: 2.1130\n",
      "Epoch 15/50\n",
      "174565/174565 [==============================] - 6s 33us/sample - loss: -100.9824 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9497 - x_pred_review_log_lambda_layer_loss: -108.3382 - x_pred_coordinates_loss: 1.9617 - val_loss: -39.0611 - val_x_pred_binary_loss: 0.1546 - val_x_pred_categorical_loss: 1.4723 - val_x_pred_review_log_lambda_layer_loss: -45.3108 - val_x_pred_coordinates_loss: 1.9705\n",
      "Epoch 16/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -101.0536 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9479 - x_pred_review_log_lambda_layer_loss: -108.4015 - x_pred_coordinates_loss: 1.9124 - val_loss: -39.8931 - val_x_pred_binary_loss: 0.1850 - val_x_pred_categorical_loss: 1.7579 - val_x_pred_review_log_lambda_layer_loss: -45.6529 - val_x_pred_coordinates_loss: -0.5193\n",
      "Epoch 17/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -101.0195 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9471 - x_pred_review_log_lambda_layer_loss: -108.3580 - x_pred_coordinates_loss: 1.8695 - val_loss: -39.2681 - val_x_pred_binary_loss: 0.1644 - val_x_pred_categorical_loss: 1.6549 - val_x_pred_review_log_lambda_layer_loss: -45.4077 - val_x_pred_coordinates_loss: 1.5956.5012 - x_pred_binary_loss: 0.4380 - x_pred_categorical_loss: 1.9470 - x_pred_review_log_la\n",
      "Epoch 18/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -101.0646 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9459 - x_pred_review_log_lambda_layer_loss: -108.3706 - x_pred_coordinates_loss: 1.8095 - val_loss: -37.9760 - val_x_pred_binary_loss: 0.1720 - val_x_pred_categorical_loss: 1.6453 - val_x_pred_review_log_lambda_layer_loss: -40.4624 - val_x_pred_coordinates_loss: 3.3730_pred_review_log_lambda_layer_loss: -108.\n",
      "Epoch 19/50\n",
      "174565/174565 [==============================] - 5s 31us/sample - loss: -101.0919 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9458 - x_pred_review_log_lambda_layer_loss: -108.3883 - x_pred_coordinates_loss: 1.7567 - val_loss: -39.7613 - val_x_pred_binary_loss: 0.1668 - val_x_pred_categorical_loss: 1.6191 - val_x_pred_review_log_lambda_layer_loss: -45.9129 - val_x_pred_coordinates_loss: 1.1214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -101.1039 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9455 - x_pred_review_log_lambda_layer_loss: -108.3824 - x_pred_coordinates_loss: 1.6821 - val_loss: -40.3570 - val_x_pred_binary_loss: 0.1925 - val_x_pred_categorical_loss: 1.5122 - val_x_pred_review_log_lambda_layer_loss: -41.0650 - val_x_pred_coordinates_loss: -0.9464459 - x_pred_review_log_lambda_layer_loss: -109.3664 - x_pred_coordi - ETA: 1s - loss: -101.8655 - x_pred_binary_loss: 0.4391 - x_pred_categorical_loss: 1.9457 - x_pred_rev\n",
      "Epoch 21/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -101.1828 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9438 - x_pred_review_log_lambda_layer_loss: -108.4758 - x_pred_coordinates_loss: 1.5928 - val_loss: -41.8697 - val_x_pred_binary_loss: 0.2209 - val_x_pred_categorical_loss: 1.6812 - val_x_pred_review_log_lambda_layer_loss: -44.8019 - val_x_pred_coordinates_loss: -1.4166\n",
      "Epoch 22/50\n",
      "174565/174565 [==============================] - 6s 34us/sample - loss: -101.1800 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9445 - x_pred_review_log_lambda_layer_loss: -108.4064 - x_pred_coordinates_loss: 1.4835 - val_loss: -39.9224 - val_x_pred_binary_loss: 0.1774 - val_x_pred_categorical_loss: 1.7519 - val_x_pred_review_log_lambda_layer_loss: -45.3538 - val_x_pred_coordinates_loss: -0.7958\n",
      "Epoch 23/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -101.2006 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9441 - x_pred_review_log_lambda_layer_loss: -108.4647 - x_pred_coordinates_loss: 1.3679 - val_loss: -40.1230 - val_x_pred_binary_loss: 0.1886 - val_x_pred_categorical_loss: 1.7110 - val_x_pred_review_log_lambda_layer_loss: -45.7651 - val_x_pred_coordinates_loss: -1.0610\n",
      "Epoch 24/50\n",
      "174565/174565 [==============================] - 6s 32us/sample - loss: -101.2405 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9429 - x_pred_review_log_lambda_layer_loss: -108.4307 - x_pred_coordinates_loss: 1.2467 - val_loss: -40.1329 - val_x_pred_binary_loss: 0.2285 - val_x_pred_categorical_loss: 1.8833 - val_x_pred_review_log_lambda_layer_loss: -44.6253 - val_x_pred_coordinates_loss: -1.4386oss: 1.9441 - x_pred_review_log_lambda_layer_los\n",
      "Epoch 25/50\n",
      "174565/174565 [==============================] - 5s 31us/sample - loss: -101.3226 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9451 - x_pred_review_log_lambda_layer_loss: -108.4604 - x_pred_coordinates_loss: 1.1562 - val_loss: -40.7432 - val_x_pred_binary_loss: 0.1685 - val_x_pred_categorical_loss: 1.5379 - val_x_pred_review_log_lambda_layer_loss: -44.4790 - val_x_pred_coordinates_loss: -1.0560\n",
      "Epoch 26/50\n",
      "174565/174565 [==============================] - 6s 33us/sample - loss: -101.3068 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9442 - x_pred_review_log_lambda_layer_loss: -108.4173 - x_pred_coordinates_loss: 1.0868 - val_loss: -41.0357 - val_x_pred_binary_loss: 0.1472 - val_x_pred_categorical_loss: 1.4515 - val_x_pred_review_log_lambda_layer_loss: -45.6707 - val_x_pred_coordinates_loss: 3.2236\n",
      "Epoch 27/50\n",
      "174565/174565 [==============================] - 6s 34us/sample - loss: -101.3480 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9435 - x_pred_review_log_lambda_layer_loss: -108.4379 - x_pred_coordinates_loss: 1.0523 - val_loss: -40.2341 - val_x_pred_binary_loss: 0.1584 - val_x_pred_categorical_loss: 1.7344 - val_x_pred_review_log_lambda_layer_loss: -45.5665 - val_x_pred_coordinates_loss: -0.7849\n",
      "Epoch 28/50\n",
      "174565/174565 [==============================] - 5s 31us/sample - loss: -101.3376 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9445 - x_pred_review_log_lambda_layer_loss: -108.4229 - x_pred_coordinates_loss: 1.0174 - val_loss: -40.4531 - val_x_pred_binary_loss: 0.1465 - val_x_pred_categorical_loss: 1.7380 - val_x_pred_review_log_lambda_layer_loss: -42.8259 - val_x_pred_coordinates_loss: 0.4866\n",
      "Epoch 29/50\n",
      "174565/174565 [==============================] - 5s 31us/sample - loss: -101.4067 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9444 - x_pred_review_log_lambda_layer_loss: -108.4518 - x_pred_coordinates_loss: 1.0068 - val_loss: -41.1230 - val_x_pred_binary_loss: 0.1994 - val_x_pred_categorical_loss: 1.6740 - val_x_pred_review_log_lambda_layer_loss: -45.9740 - val_x_pred_coordinates_loss: -1.7953\n",
      "Epoch 30/50\n",
      "174565/174565 [==============================] - 5s 30us/sample - loss: -101.4204 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9447 - x_pred_review_log_lambda_layer_loss: -108.4458 - x_pred_coordinates_loss: 0.9884 - val_loss: -40.2841 - val_x_pred_binary_loss: 0.1988 - val_x_pred_categorical_loss: 1.7482 - val_x_pred_review_log_lambda_layer_loss: -45.6346 - val_x_pred_coordinates_loss: -1.6713\n",
      "Epoch 31/50\n",
      "174565/174565 [==============================] - 5s 30us/sample - loss: -101.4063 - x_pred_binary_loss: 0.4379 - x_pred_categorical_loss: 1.9447 - x_pred_review_log_lambda_layer_loss: -108.4267 - x_pred_coordinates_loss: 0.9650 - val_loss: -40.5110 - val_x_pred_binary_loss: 0.1403 - val_x_pred_categorical_loss: 1.4731 - val_x_pred_review_log_lambda_layer_loss: -45.8996 - val_x_pred_coordinates_loss: 2.2764\n",
      "Epoch 32/50\n",
      "174565/174565 [==============================] - 5s 31us/sample - loss: -101.4668 - x_pred_binary_loss: 0.4378 - x_pred_categorical_loss: 1.9440 - x_pred_review_log_lambda_layer_loss: -108.4895 - x_pred_coordinates_loss: 0.9575 - val_loss: -40.8874 - val_x_pred_binary_loss: 0.1938 - val_x_pred_categorical_loss: 1.6697 - val_x_pred_review_log_lambda_layer_loss: -45.7949 - val_x_pred_coordinates_loss: -1.6871\n",
      "Epoch 33/50\n",
      "174565/174565 [==============================] - 5s 30us/sample - loss: -101.4526 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9447 - x_pred_review_log_lambda_layer_loss: -108.4433 - x_pred_coordinates_loss: 0.9352 - val_loss: -40.6219 - val_x_pred_binary_loss: 0.1569 - val_x_pred_categorical_loss: 1.7284 - val_x_pred_review_log_lambda_layer_loss: -44.3730 - val_x_pred_coordinates_loss: -0.2823\n",
      "Epoch 34/50\n",
      "174565/174565 [==============================] - 5s 30us/sample - loss: -101.5363 - x_pred_binary_loss: 0.4378 - x_pred_categorical_loss: 1.9445 - x_pred_review_log_lambda_layer_loss: -108.5261 - x_pred_coordinates_loss: 0.9128 - val_loss: -40.6009 - val_x_pred_binary_loss: 0.1728 - val_x_pred_categorical_loss: 1.6146 - val_x_pred_review_log_lambda_layer_loss: -45.9686 - val_x_pred_coordinates_loss: -1.1822\n",
      "Epoch 35/50\n",
      "174565/174565 [==============================] - 5s 31us/sample - loss: -101.5211 - x_pred_binary_loss: 0.4378 - x_pred_categorical_loss: 1.9442 - x_pred_review_log_lambda_layer_loss: -108.4873 - x_pred_coordinates_loss: 0.9018 - val_loss: -41.0738 - val_x_pred_binary_loss: 0.1413 - val_x_pred_categorical_loss: 1.5038 - val_x_pred_review_log_lambda_layer_loss: -45.5608 - val_x_pred_coordinates_loss: 0.9610\n",
      "Epoch 36/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -101.5303 - x_pred_binary_loss: 0.4378 - x_pred_categorical_loss: 1.9442 - x_pred_review_log_lambda_layer_loss: -108.4767 - x_pred_coordinates_loss: 0.8714 - val_loss: -40.5280 - val_x_pred_binary_loss: 0.1517 - val_x_pred_categorical_loss: 1.4937 - val_x_pred_review_log_lambda_layer_loss: -45.9528 - val_x_pred_coordinates_loss: 2.1487\n",
      "Epoch 37/50\n",
      "174565/174565 [==============================] - 8s 45us/sample - loss: -101.5647 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9438 - x_pred_review_log_lambda_layer_loss: -108.5225 - x_pred_coordinates_loss: 0.8443 - val_loss: -40.4495 - val_x_pred_binary_loss: 0.1769 - val_x_pred_categorical_loss: 1.7181 - val_x_pred_review_log_lambda_layer_loss: -45.2834 - val_x_pred_coordinates_loss: -1.2362\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174565/174565 [==============================] - 7s 39us/sample - loss: -101.5082 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9437 - x_pred_review_log_lambda_layer_loss: -108.4473 - x_pred_coordinates_loss: 0.8286 - val_loss: -41.1551 - val_x_pred_binary_loss: 0.1484 - val_x_pred_categorical_loss: 1.5653 - val_x_pred_review_log_lambda_layer_loss: -45.2385 - val_x_pred_coordinates_loss: 0.7243\n",
      "Epoch 39/50\n",
      "174565/174565 [==============================] - 7s 40us/sample - loss: -101.5418 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9442 - x_pred_review_log_lambda_layer_loss: -108.5038 - x_pred_coordinates_loss: 0.8007 - val_loss: -40.6909 - val_x_pred_binary_loss: 0.1695 - val_x_pred_categorical_loss: 1.6634 - val_x_pred_review_log_lambda_layer_loss: -45.9858 - val_x_pred_coordinates_loss: -1.1940\n",
      "Epoch 40/50\n",
      "174565/174565 [==============================] - 10s 59us/sample - loss: -101.5940 - x_pred_binary_loss: 0.4376 - x_pred_categorical_loss: 1.9429 - x_pred_review_log_lambda_layer_loss: -108.5046 - x_pred_coordinates_loss: 0.7716 - val_loss: -40.5081 - val_x_pred_binary_loss: 0.1809 - val_x_pred_categorical_loss: 1.6049 - val_x_pred_review_log_lambda_layer_loss: -45.3384 - val_x_pred_coordinates_loss: -1.6492\n",
      "Epoch 41/50\n",
      "174565/174565 [==============================] - 7s 40us/sample - loss: -101.6181 - x_pred_binary_loss: 0.4375 - x_pred_categorical_loss: 1.9436 - x_pred_review_log_lambda_layer_loss: -108.5221 - x_pred_coordinates_loss: 0.7379 - val_loss: -39.4571 - val_x_pred_binary_loss: 0.1706 - val_x_pred_categorical_loss: 1.5267 - val_x_pred_review_log_lambda_layer_loss: -43.4381 - val_x_pred_coordinates_loss: -1.5503\n",
      "Epoch 42/50\n",
      "174565/174565 [==============================] - 7s 39us/sample - loss: -101.5778 - x_pred_binary_loss: 0.4378 - x_pred_categorical_loss: 1.9431 - x_pred_review_log_lambda_layer_loss: -108.4729 - x_pred_coordinates_loss: 0.7183 - val_loss: -40.1255 - val_x_pred_binary_loss: 0.1911 - val_x_pred_categorical_loss: 1.7126 - val_x_pred_review_log_lambda_layer_loss: -45.3215 - val_x_pred_coordinates_loss: -1.7089\n",
      "Epoch 43/50\n",
      "174565/174565 [==============================] - 7s 37us/sample - loss: -101.6089 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9432 - x_pred_review_log_lambda_layer_loss: -108.5043 - x_pred_coordinates_loss: 0.6875 - val_loss: -40.3082 - val_x_pred_binary_loss: 0.1944 - val_x_pred_categorical_loss: 1.6860 - val_x_pred_review_log_lambda_layer_loss: -45.7990 - val_x_pred_coordinates_loss: -1.9937\n",
      "Epoch 44/50\n",
      "174565/174565 [==============================] - 7s 39us/sample - loss: -101.6732 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9425 - x_pred_review_log_lambda_layer_loss: -108.5326 - x_pred_coordinates_loss: 0.6641 - val_loss: -41.3826 - val_x_pred_binary_loss: 0.1438 - val_x_pred_categorical_loss: 1.4942 - val_x_pred_review_log_lambda_layer_loss: -45.7600 - val_x_pred_coordinates_loss: 1.0803\n",
      "Epoch 45/50\n",
      "174565/174565 [==============================] - 11s 63us/sample - loss: -101.4152 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9427 - x_pred_review_log_lambda_layer_loss: -108.2934 - x_pred_coordinates_loss: 0.6440 - val_loss: -41.3440 - val_x_pred_binary_loss: 0.1536 - val_x_pred_categorical_loss: 1.5956 - val_x_pred_review_log_lambda_layer_loss: -44.5169 - val_x_pred_coordinates_loss: -0.8964ary_loss: 0.4356 - x_pred_categorical_loss: 1.9445 - x_pred_review_lo\n",
      "Epoch 46/50\n",
      "174565/174565 [==============================] - 14s 81us/sample - loss: -101.5702 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9423 - x_pred_review_log_lambda_layer_loss: -108.4124 - x_pred_coordinates_loss: 0.6217 - val_loss: -40.8910 - val_x_pred_binary_loss: 0.1743 - val_x_pred_categorical_loss: 1.6928 - val_x_pred_review_log_lambda_layer_loss: -45.7228 - val_x_pred_coordinates_loss: -1.4554\n",
      "Epoch 47/50\n",
      "174565/174565 [==============================] - 7s 42us/sample - loss: -101.6851 - x_pred_binary_loss: 0.4373 - x_pred_categorical_loss: 1.9422 - x_pred_review_log_lambda_layer_loss: -108.5169 - x_pred_coordinates_loss: 0.5877 - val_loss: -42.2131 - val_x_pred_binary_loss: 0.1406 - val_x_pred_categorical_loss: 1.5710 - val_x_pred_review_log_lambda_layer_loss: -45.8501 - val_x_pred_coordinates_loss: 0.0433\n",
      "Epoch 48/50\n",
      "174565/174565 [==============================] - 7s 41us/sample - loss: -101.7031 - x_pred_binary_loss: 0.4375 - x_pred_categorical_loss: 1.9423 - x_pred_review_log_lambda_layer_loss: -108.5520 - x_pred_coordinates_loss: 0.5594 - val_loss: -40.8011 - val_x_pred_binary_loss: 0.1793 - val_x_pred_categorical_loss: 1.6708 - val_x_pred_review_log_lambda_layer_loss: -45.9573 - val_x_pred_coordinates_loss: -1.7323\n",
      "Epoch 49/50\n",
      "174565/174565 [==============================] - 8s 45us/sample - loss: -101.6750 - x_pred_binary_loss: 0.4376 - x_pred_categorical_loss: 1.9419 - x_pred_review_log_lambda_layer_loss: -108.4852 - x_pred_coordinates_loss: 0.5484 - val_loss: -40.8203 - val_x_pred_binary_loss: 0.1790 - val_x_pred_categorical_loss: 1.6059 - val_x_pred_review_log_lambda_layer_loss: -45.3171 - val_x_pred_coordinates_loss: -1.5543\n",
      "Epoch 50/50\n",
      "174565/174565 [==============================] - 7s 41us/sample - loss: -101.6968 - x_pred_binary_loss: 0.4377 - x_pred_categorical_loss: 1.9424 - x_pred_review_log_lambda_layer_loss: -108.5175 - x_pred_coordinates_loss: 0.5095 - val_loss: -40.5498 - val_x_pred_binary_loss: 0.1882 - val_x_pred_categorical_loss: 1.6673 - val_x_pred_review_log_lambda_layer_loss: -45.8950 - val_x_pred_coordinates_loss: -1.8824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x143d03048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(train_dataset , [train_binary_labels, train_categorical_labels, train_review_labels, train_coordinates_labels], shuffle = True, epochs = epochs, batch_size = batch_size, validation_data=(test_dataset , [test_binary_labels, test_categorical_labels, test_review_labels, test_coordinates_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_input = Input(shape=(latent_dim, ), name = 'decode_input')\n",
    "decode_layer_1 = decode_1(decode_input)\n",
    "decode_layer_2 = decode_2(decode_layer_1)\n",
    "\n",
    "# decode_x_pred_coordinates=x_pred_coordinates_mdn_layer(decode_layer_2)\n",
    "x_pred_coordinates_mu = x_pred_coordinates_mu_layer(decode_layer_2)\n",
    "x_pred_coordinates_log_var = x_pred_coordinates_log_var_layer(decode_layer_2)\n",
    "decode_x_pred_coordinates = x_pred_coordinates_layer([x_pred_coordinates_mu, x_pred_coordinates_log_var])\n",
    "\n",
    "decode_x_pred_review = x_pred_review_log_lambda_layer(decode_layer_2)\n",
    "\n",
    "decode_x_pred_binary = x_pred_binary_layer(decode_layer_2) # binary cross entropy\n",
    "decode_x_pred_categorical = x_pred_categorical_layer(decode_layer_2) # categorical cross entropy\n",
    "\n",
    "\n",
    "decoder = Model(decode_input, [decode_x_pred_coordinates, decode_x_pred_review, decode_x_pred_categorical, decode_x_pred_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'InputLayer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8ad28151f4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m SVG(model_to_dot(decoder, show_shapes=True)\n\u001b[0m\u001b[1;32m      2\u001b[0m     .create(prog='dot', format='svg'))\n",
      "\u001b[0;32m~/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mnode_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ib-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minbound_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0minbound_layer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'InputLayer' object is not iterable"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(decoder, show_shapes=True)\n",
    "    .create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Models and Metadata\n",
    "#### Saving Models (Actually, only the decoder matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = vae.to_json()\n",
    "with open(\"./model/vae_full_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "vae.save_weights(\"./model/vae_full_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# encoder = Model(x, [z_mu, z_log_var])\n",
    "model_json = encoder.to_json()\n",
    "with open(\"./model/vae_encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "encoder.save_weights(\"./model/vae_encoder.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model_json = decoder.to_json()\n",
    "with open(\"./model/vae_decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "decoder.save_weights(\"./model/vae_decoder.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating some Samples for Testing\n",
    "#### Functions for data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "def sample(model, input_mu, input_log_var, samples_per_z=1):\n",
    "    multiplied_input_mu = np.repeat(input_mu, samples_per_z, axis=0)\n",
    "    multiplied_input_log_var = np.repeat(input_log_var, samples_per_z, axis=0)\n",
    "    eps = np.random.normal(size=(multiplied_input_mu.shape[0], latent_dim))\n",
    "    z = reparameterize(multiplied_input_mu, multiplied_input_log_var, eps)\n",
    "    predictions = model.predict(z, batch_size = None, steps = 1)\n",
    "    return reconstruct(predictions)\n",
    "    \n",
    "def reconstruct(predictions):\n",
    "    coordinates, review, categorical, binary = predictions\n",
    "    \n",
    "    # coordinates handled here\n",
    "    print(coordinates.shape)\n",
    "#     coordinates_data = np.apply_along_axis(mdn.sample_from_output, 1, coordinates, OUTPUT_DIMS, N_MIXES, temp=1.0)\n",
    "#     coordinates_data = np.squeeze(coordinates_data, axis=1)\n",
    "    mu, log_var = np.split(coordinates, indices_or_sections = 2,axis = 1)\n",
    "    eps = np.random.normal(size=mu.shape)\n",
    "    coordinates_data = reparameterize(mu, log_var, eps)\n",
    "    scaler = load(open('./model/standard_scaler.pkl', 'rb'))\n",
    "    coordinates_data = scaler.inverse_transform(coordinates_data)\n",
    "    print(coordinates_data.shape)\n",
    "    \n",
    "    for i, c in enumerate(coordinates_data):\n",
    "        if c[0] > 180.0:\n",
    "            coordinates_data[i][0]= 180.0\n",
    "        if c[0] < -180.0:\n",
    "            coordinates_data[i][0]= -180.0\n",
    "        if c[1] > 180.0:\n",
    "            coordinates_data[i][1]= 180.0\n",
    "        if c[1] < -180.0:\n",
    "            coordinates_data[i][1]= -180.0\n",
    "    \n",
    "    ## review_count handled here\n",
    "    exp_log_review = np.exp(review)\n",
    "    review_data = np.random.poisson(lam=exp_log_review, size = review.shape)\n",
    "    for i, r in enumerate(review_data):\n",
    "        if r[0] < 0:\n",
    "            review_data[i][0] = 0\n",
    "        review_data[i][0] = float(int(review_data[i][0]))\n",
    "    \n",
    "    categorical = np.apply_along_axis(lambda t : np.random.multinomial(1,t), -1, categorical)\n",
    "    categorical = np.apply_along_axis(lambda t : np.argmax(t), -1, categorical)\n",
    "    categorical = np.expand_dims(categorical, axis = -1)\n",
    "    categorical_data = np.apply_along_axis(lambda t : float(reverse_categorical_map[t[0]]), -1, categorical)\n",
    "    categorical_data = np.expand_dims(categorical_data, axis = -1)\n",
    "    binary_data = np.apply_along_axis(lambda t: np.random.binomial(1, t), -1, binary)\n",
    "#     coordinates, reviews = np.split(continuous_data, indices_or_sections=[2], axis = 1)\n",
    "    return np.concatenate([coordinates_data, categorical_data, review_data, binary_data], axis = 1)\n",
    "    \n",
    "\n",
    "def reparameterize(input_mu, input_log_var, eps):\n",
    "    sigma = np.exp(0.5*input_log_var)\n",
    "    return eps*sigma + input_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Samples\n",
    "Make use of the funciton sample to generate samples with our model. U need to supply an array of mu and their respective log var in a separate array to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n",
      "(10000, 4)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "vae_sample = train_dataset[np.random.choice(len(train_dataset), size=10000, replace=False)]\n",
    "# vae_sample_mu, vae_sample_log_var = encoder.predict(vae_sample, batch_size=batch_size)\n",
    "\n",
    "test = encoder.predict(vae_sample, batch_size=batch_size)\n",
    "print(test.shape)\n",
    "# np.save('./model/sample_mu.npy', vae_sample_mu)\n",
    "# np.save('./model/sample_log_var.npy', vae_sample_log_var)\n",
    "\n",
    "predictions = decoder.predict(test, batch_size = None, steps = 1)\n",
    "vae_samples = reconstruct(predictions)\n",
    "file_name = './samples/vae_6_2_sample_' + str(len(vae_samples)) + '.csv'\n",
    "np.savetxt(file_name, vae_samples, delimiter = ',', header='latitude,longitude,stars,review_count,is_open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "# vae_samples = sample(decoder, vae_sample_mu, vae_sample_log_var)\n",
    "\n",
    "# # Saving the samples in a separate file\n",
    "# file_name = './samples/vae_8_sample_' + str(len(vae_samples)) + '.csv'\n",
    "# np.savetxt(file_name, vae_samples, delimiter = ',', header='latitude,longitude,stars,review_count,is_open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  36.12722656, -114.97610985,    1.        ,    0.        ,\n",
       "           1.        ],\n",
       "       [  43.64995768,  -79.71934736,    4.        ,    2.        ,\n",
       "           1.        ],\n",
       "       [  41.24716502,  -82.14576402,    3.        ,    3.        ,\n",
       "           1.        ],\n",
       "       [  38.83486706,  -81.44808577,    1.        ,    1.        ,\n",
       "           1.        ],\n",
       "       [  33.52494004, -112.20338825,    5.        ,    6.        ,\n",
       "           1.        ],\n",
       "       [  43.83154703,  -79.53044245,    3.        ,    4.        ,\n",
       "           1.        ],\n",
       "       [  33.47541187, -111.71694681,    5.        ,    3.        ,\n",
       "           1.        ],\n",
       "       [  43.03446893,  -80.8353163 ,    1.5       ,    3.        ,\n",
       "           1.        ],\n",
       "       [  45.55855775,  -73.54997901,    2.        ,    7.        ,\n",
       "           1.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_samples[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
