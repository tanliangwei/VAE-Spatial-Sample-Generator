{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "In this notebook, we will train our VAE model. This involves:\n",
    "\n",
    "1. Encoder\n",
    "2. Decoder\n",
    "3. Full Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "We will be using Keras to build and train our VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.utils.vis_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f0e1f2c458e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormatStrFormatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.utils.vis_utils'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%matplotlib notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "import h5py\n",
    "\n",
    "# import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer, Add, Multiply, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import model_from_json\n",
    "# import mdn\n",
    "\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from pickle import dump, load\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Constants\n",
    "Hyper parameters and constants will all be located here for ease of adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_dim = 11\n",
    "categorical_map = {0:0, 0.5:1, 1: 2, 1.5:3, 2:4, 2.5:5, 3:6, 3.5:7, 4:8, 4.5:9, 5:10}\n",
    "reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "continuous_dim = 3\n",
    "binary_dim = 1\n",
    "original_dim = binary_dim + continuous_dim + categorical_dim\n",
    "intermediate_dim_1 = 50\n",
    "intermediate_dim_2 = 50\n",
    "latent_dim = 4\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "## Constants for the Mixture layer\n",
    "N_HIDDEN = 15  # number of hidden units in the Dense layer\n",
    "N_MIXES = 10  # number of mixture components\n",
    "OUTPUT_DIMS = 2  # number of real-values predicted by each mixture component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "We have to write our own custom layer and custom loss function as these are not supported on Keras natively. There are a few things to be done:\n",
    "\n",
    "1. Custom KLDivergence Layer\n",
    "2. Custom Loss Functions\n",
    "3. Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence Layer\n",
    "To ensure modularity, we decided to create a separate layer for KL Divergence. This layer will account for the loss required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Functions\n",
    "As the yelp dataset contains binary, categorical as well as continuous data, we will build 3 custom loss functions.\n",
    "\n",
    "#### Binary Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y_true, y_pred):\n",
    "\t# input dimension is (batchsize, 1)\n",
    "    return K.binary_crossentropy(y_true, y_pred) # the dimension of return value is (batchsize , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_loss(y_true, y_pred):\n",
    "\t# input dimension is (batchsize, number of categories)\n",
    "  return K.categorical_crossentropy(y_true, y_pred) # the dimension of return value is (batchsize , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis) # return a tensor of shape (batch_size, 1)\n",
    "\n",
    "# Added a postfix because now we also have poisson as a distribution\n",
    "def continuous_loss_gaussian(y_true, y_pred):\n",
    "\t# need to return log probability for continuous gaussian loss.\n",
    "\t# will get a (batchsize, 6 continuous variable input) where 3 of the 6 represents mu and the others logvar\n",
    "\t# y_true will be (batchsize, 3)\n",
    "  mu, logvar = tf.split(y_pred, num_or_size_splits = 2, axis = 1)\n",
    "  return -1 * log_normal_pdf(y_true, mu, logvar) \n",
    "\n",
    "def continuous_loss_poisson(y_true, y_pred):\n",
    "\t# need to return log probability for continuous poisson loss.\n",
    "\t# will get a (batchsize, 6 continuous variable input) where 3 of the 6 represents mu and the others logvar\n",
    "\t# y_true will be (batchsize, 3)\n",
    "  return tf.nn.log_poisson_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "- tanh/sigmoid is used because Relu resulted in loss going to infinity\n",
    "- going to delete review_log_var and review_mu since we are trying out the Poission distribution which only takes 1 parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "import mdn\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "input_shape = (original_dim,)\n",
    "base_depth = 32\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dim), scale=1), reinterpreted_batch_ndims=1)\n",
    "\n",
    "## Encoder\n",
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=input_shape),\n",
    "    tfkl.Dense(intermediate_dim_1, activation='tanh', name='hidden_enc_1'),\n",
    "    tfkl.Dense(intermediate_dim_2, activation='tanh', name='hidden_enc_2'),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim), activation=None),\n",
    "    tfpl.MultivariateNormalTriL( latent_dim, activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
    "])\n",
    "\n",
    "\n",
    "decode_1 = tfkl.Dense(intermediate_dim_2, activation='tanh', name='hidden_dec_2')\n",
    "h_dec = decode_1(encoder.outputs[0])\n",
    "\n",
    "decode_2 = tfkl.Dense(intermediate_dim_1, activation='tanh', name='hidden_dec_1')\n",
    "h_dec = decode_2(h_dec)\n",
    "\n",
    "x_pred_coordinates_mdn_layer = mdn.MDN(OUTPUT_DIMS, N_MIXES, name = 'x_pred_coordinates_mdn_layer')\n",
    "x_pred_coordinates = x_pred_coordinates_mdn_layer(h_dec)\n",
    "\n",
    "## Old coordinates layer\n",
    "# x_pred_coordinates_mu_layer = tfkl.Dense(2, name='x_pred_coordinates_mu')\n",
    "# x_pred_coordinates_mu = x_pred_coordinates_mu_layer(h_dec)\n",
    "\n",
    "# x_pred_coordinates_log_var_layer = tfkl.Dense(2, name='x_pred_coordinates_log_var')\n",
    "# x_pred_coordinates_log_var = x_pred_coordinates_log_var_layer(h_dec)\n",
    "\n",
    "# x_pred_coordinates_layer = tfkl.Concatenate(axis=-1, name = 'x_pred_coordinates')\n",
    "# x_pred_coordinates = x_pred_coordinates_layer([x_pred_coordinates_mu, x_pred_coordinates_log_var])\n",
    "\n",
    "## This outputs the lambda require for poisson distribution and thats all that we need\n",
    "x_pred_review_log_lambda_layer = tfkl.Dense(1,name = 'x_pred_review_log_lambda_layer')\n",
    "x_pred_review = x_pred_review_log_lambda_layer(h_dec)\n",
    "\n",
    "x_pred_binary_layer = tfkl.Dense(binary_dim, activation='sigmoid', name='x_pred_binary')\n",
    "x_pred_binary = x_pred_binary_layer(h_dec) # binary cross entropy\n",
    "\n",
    "x_pred_categorical_layer = tfkl.Dense(categorical_dim, activation='softmax', name='x_pred_categorical')\n",
    "x_pred_categorical = x_pred_categorical_layer(h_dec) # categorical cross entropy\n",
    "\n",
    "vae = tfk.Model(inputs=encoder.inputs, outputs=[x_pred_binary, x_pred_categorical, x_pred_review, x_pred_coordinates])\n",
    "# vae = tfk.Model(inputs=encoder.inputs,\n",
    "#                 outputs=decoder(encoder.outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Model and Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "vae.compile(optimizer=optimizer, loss=[binary_loss, categorical_loss, continuous_loss_poisson, mdn.get_mixture_loss_func(OUTPUT_DIMS,N_MIXES)], loss_weights=[1, 1, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc_1 (Dense)            (None, 50)           800         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc_2 (Dense)            (None, 50)           2550        hidden_enc_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 14)           714         hidden_enc_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multivariate_normal_tri_l_3 (Mu ((None, 4), (None, 4 0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec_2 (Dense)            (None, 50)           250         multivariate_normal_tri_l_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec_1 (Dense)            (None, 50)           2550        hidden_dec_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_binary (Dense)           (None, 1)            51          hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_categorical (Dense)      (None, 11)           561         hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_review_log_lambda_layer  (None, 1)            51          hidden_dec_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "x_pred_coordinates_mdn_layer (M (None, 50)           2550        hidden_dec_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,077\n",
      "Trainable params: 10,077\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt('../../datasets/yelp_business.csv',delimiter=',',skip_header=1)\n",
    "dataset = dataset[~np.isnan(dataset).any(axis=1)]\n",
    "test_set, train_set = np.split(dataset,[1], axis = 0)\n",
    "\n",
    "def format_data(dataset, scaler_to_use=None ,save_scaler=True):\n",
    "    # handling the categorical variables\n",
    "    coordinates, ratings, reviews, is_opens = np.split(dataset, [2, 3, 4], axis = 1)\n",
    "    one_hot_array = np.zeros((ratings.shape[0], categorical_dim))\n",
    "\n",
    "    for i, r in enumerate(ratings):\n",
    "        one_hot_array[i][categorical_map[r[0]]] = 1\n",
    "    \n",
    "    # handling coordinates\n",
    "    if scaler_to_use is None:\n",
    "        scaler_to_use = preprocessing.StandardScaler()\n",
    "        scaler_to_use.fit(coordinates)\n",
    "    \n",
    "    coordinates = scaler_to_use.transform(coordinates)\n",
    "    \n",
    "    if save_scaler:\n",
    "        dump(scaler_to_use, open('./model/standard_scaler.pkl', 'wb'))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for i, c in enumerate(coordinates):\n",
    "#         coordinates[i][0] = (c[0]+180)/360\n",
    "#         coordinates[i][1] = (c[1]+180)/360\n",
    "\n",
    "    dataset = np.concatenate((coordinates, reviews, is_opens, one_hot_array), axis = 1)\n",
    "\n",
    "    # creating the labels\n",
    "    coordinates_labels = coordinates\n",
    "    review_labels = reviews\n",
    "    categorical_labels = one_hot_array\n",
    "    binary_labels = is_opens\n",
    "    return dataset, coordinates_labels, review_labels, categorical_labels, binary_labels\n",
    "\n",
    "train_dataset, train_coordinates_labels, train_review_labels, train_categorical_labels, train_binary_labels = format_data(train_set)\n",
    "\n",
    "## Open scaler\n",
    "scaler = load(open('./model/standard_scaler.pkl', 'rb'))\n",
    "test_dataset, test_coordinates_labels, test_review_labels, test_categorical_labels, test_binary_labels = format_data(test_set, scaler, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Review_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(train_review_labels, 1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174565 samples, validate on 1 samples\n",
      "Epoch 1/50\n",
      "174565/174565 [==============================] - 17s 97us/sample - loss: -89.9459 - x_pred_binary_loss: 0.5043 - x_pred_categorical_loss: 2.1485 - x_pred_review_log_lambda_layer_loss: -98.5309 - x_pred_coordinates_mdn_layer_loss: 1.8392 - val_loss: -43.6719 - val_x_pred_binary_loss: 0.1467 - val_x_pred_categorical_loss: 1.4049 - val_x_pred_review_log_lambda_layer_loss: -45.8876 - val_x_pred_coordinates_mdn_layer_loss: -0.1929\n",
      "Epoch 2/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -101.3797 - x_pred_binary_loss: 0.4547 - x_pred_categorical_loss: 2.0217 - x_pred_review_log_lambda_layer_loss: -107.9093 - x_pred_coordinates_mdn_layer_loss: 0.6540 - val_loss: -41.9807 - val_x_pred_binary_loss: 0.1930 - val_x_pred_categorical_loss: 1.4972 - val_x_pred_review_log_lambda_layer_loss: -45.4995 - val_x_pred_coordinates_mdn_layer_loss: -1.7144\n",
      "Epoch 3/50\n",
      "174565/174565 [==============================] - 10s 56us/sample - loss: -103.1918 - x_pred_binary_loss: 0.4414 - x_pred_categorical_loss: 1.9908 - x_pred_review_log_lambda_layer_loss: -108.1635 - x_pred_coordinates_mdn_layer_loss: -0.5517 - val_loss: -43.4466 - val_x_pred_binary_loss: 0.1619 - val_x_pred_categorical_loss: 1.4504 - val_x_pred_review_log_lambda_layer_loss: -45.0545 - val_x_pred_coordinates_mdn_layer_loss: -4.1799\n",
      "Epoch 4/50\n",
      "174565/174565 [==============================] - 11s 62us/sample - loss: -104.2186 - x_pred_binary_loss: 0.4387 - x_pred_categorical_loss: 1.9781 - x_pred_review_log_lambda_layer_loss: -108.2686 - x_pred_coordinates_mdn_layer_loss: -1.2293 - val_loss: -44.9433 - val_x_pred_binary_loss: 0.1598 - val_x_pred_categorical_loss: 1.6895 - val_x_pred_review_log_lambda_layer_loss: -42.3855 - val_x_pred_coordinates_mdn_layer_loss: -4.4560\n",
      "Epoch 5/50\n",
      "174565/174565 [==============================] - 13s 76us/sample - loss: -104.9342 - x_pred_binary_loss: 0.4389 - x_pred_categorical_loss: 1.9724 - x_pred_review_log_lambda_layer_loss: -108.2836 - x_pred_coordinates_mdn_layer_loss: -1.7368 - val_loss: -44.4782 - val_x_pred_binary_loss: 0.1539 - val_x_pred_categorical_loss: 1.4771 - val_x_pred_review_log_lambda_layer_loss: -45.9071 - val_x_pred_coordinates_mdn_layer_loss: -4.1574\n",
      "Epoch 6/50\n",
      "174565/174565 [==============================] - 12s 68us/sample - loss: -105.7647 - x_pred_binary_loss: 0.4388 - x_pred_categorical_loss: 1.9714 - x_pred_review_log_lambda_layer_loss: -108.3170 - x_pred_coordinates_mdn_layer_loss: -2.4850 - val_loss: -45.7926 - val_x_pred_binary_loss: 0.1634 - val_x_pred_categorical_loss: 1.4771 - val_x_pred_review_log_lambda_layer_loss: -45.9181 - val_x_pred_coordinates_mdn_layer_loss: -5.2657\n",
      "Epoch 7/50\n",
      "174565/174565 [==============================] - 10s 60us/sample - loss: -106.1066 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9706 - x_pred_review_log_lambda_layer_loss: -108.3469 - x_pred_coordinates_mdn_layer_loss: -2.7287 - val_loss: -46.7188 - val_x_pred_binary_loss: 0.1854 - val_x_pred_categorical_loss: 1.5499 - val_x_pred_review_log_lambda_layer_loss: -44.1957 - val_x_pred_coordinates_mdn_layer_loss: -5.2947\n",
      "Epoch 8/50\n",
      "174565/174565 [==============================] - 19s 108us/sample - loss: -106.2522 - x_pred_binary_loss: 0.4387 - x_pred_categorical_loss: 1.9704 - x_pred_review_log_lambda_layer_loss: -108.3320 - x_pred_coordinates_mdn_layer_loss: -2.8521 - val_loss: -44.8391 - val_x_pred_binary_loss: 0.1697 - val_x_pred_categorical_loss: 1.6087 - val_x_pred_review_log_lambda_layer_loss: -44.6553 - val_x_pred_coordinates_mdn_layer_loss: -4.4626\n",
      "Epoch 9/50\n",
      "174565/174565 [==============================] - 10s 59us/sample - loss: -106.3705 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9698 - x_pred_review_log_lambda_layer_loss: -108.3740 - x_pred_coordinates_mdn_layer_loss: -2.9307 - val_loss: -45.3144 - val_x_pred_binary_loss: 0.1519 - val_x_pred_categorical_loss: 1.4543 - val_x_pred_review_log_lambda_layer_loss: -45.1225 - val_x_pred_coordinates_mdn_layer_loss: -5.0652\n",
      "Epoch 10/50\n",
      "174565/174565 [==============================] - 11s 62us/sample - loss: -106.4630 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9694 - x_pred_review_log_lambda_layer_loss: -108.3581 - x_pred_coordinates_mdn_layer_loss: -2.9886 - val_loss: -46.3805 - val_x_pred_binary_loss: 0.1748 - val_x_pred_categorical_loss: 1.4602 - val_x_pred_review_log_lambda_layer_loss: -45.8259 - val_x_pred_coordinates_mdn_layer_loss: -5.0245\n",
      "Epoch 11/50\n",
      "174565/174565 [==============================] - 13s 73us/sample - loss: -106.5024 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9695 - x_pred_review_log_lambda_layer_loss: -108.3448 - x_pred_coordinates_mdn_layer_loss: -3.0269 - val_loss: -45.7048 - val_x_pred_binary_loss: 0.1578 - val_x_pred_categorical_loss: 1.5272 - val_x_pred_review_log_lambda_layer_loss: -45.9355 - val_x_pred_coordinates_mdn_layer_loss: -4.7772\n",
      "Epoch 12/50\n",
      "174565/174565 [==============================] - 14s 81us/sample - loss: -106.5846 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9691 - x_pred_review_log_lambda_layer_loss: -108.3828 - x_pred_coordinates_mdn_layer_loss: -3.0528 - val_loss: -46.6001 - val_x_pred_binary_loss: 0.1518 - val_x_pred_categorical_loss: 1.3951 - val_x_pred_review_log_lambda_layer_loss: -42.4058 - val_x_pred_coordinates_mdn_layer_loss: -4.7661\n",
      "Epoch 13/50\n",
      "174565/174565 [==============================] - 14s 80us/sample - loss: -106.4855 - x_pred_binary_loss: 0.4386 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.2659 - x_pred_coordinates_mdn_layer_loss: -3.0798 - val_loss: -46.2648 - val_x_pred_binary_loss: 0.1631 - val_x_pred_categorical_loss: 1.6307 - val_x_pred_review_log_lambda_layer_loss: -44.4382 - val_x_pred_coordinates_mdn_layer_loss: -4.6915\n",
      "Epoch 14/50\n",
      "174565/174565 [==============================] - 12s 70us/sample - loss: -106.6132 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9688 - x_pred_review_log_lambda_layer_loss: -108.3534 - x_pred_coordinates_mdn_layer_loss: -3.0904 - val_loss: -45.6628 - val_x_pred_binary_loss: 0.1546 - val_x_pred_categorical_loss: 1.4816 - val_x_pred_review_log_lambda_layer_loss: -45.7091 - val_x_pred_coordinates_mdn_layer_loss: -4.8832\n",
      "Epoch 15/50\n",
      "174565/174565 [==============================] - 12s 68us/sample - loss: -106.6572 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9687 - x_pred_review_log_lambda_layer_loss: -108.3896 - x_pred_coordinates_mdn_layer_loss: -3.1038 - val_loss: -46.1324 - val_x_pred_binary_loss: 0.1657 - val_x_pred_categorical_loss: 1.4872 - val_x_pred_review_log_lambda_layer_loss: -45.9989 - val_x_pred_coordinates_mdn_layer_loss: -4.8958\n",
      "Epoch 16/50\n",
      "174565/174565 [==============================] - 12s 70us/sample - loss: -106.6772 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9689 - x_pred_review_log_lambda_layer_loss: -108.3900 - x_pred_coordinates_mdn_layer_loss: -3.1149 - val_loss: -45.6843 - val_x_pred_binary_loss: 0.1645 - val_x_pred_categorical_loss: 1.4148 - val_x_pred_review_log_lambda_layer_loss: -45.0758 - val_x_pred_coordinates_mdn_layer_loss: -4.8641\n",
      "Epoch 17/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -106.6983 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9690 - x_pred_review_log_lambda_layer_loss: -108.3880 - x_pred_coordinates_mdn_layer_loss: -3.1196 - val_loss: -46.9492 - val_x_pred_binary_loss: 0.1716 - val_x_pred_categorical_loss: 1.5555 - val_x_pred_review_log_lambda_layer_loss: -44.7691 - val_x_pred_coordinates_mdn_layer_loss: -4.5667\n",
      "Epoch 18/50\n",
      "174565/174565 [==============================] - 11s 63us/sample - loss: -106.6885 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9688 - x_pred_review_log_lambda_layer_loss: -108.3835 - x_pred_coordinates_mdn_layer_loss: -3.1271 - val_loss: -46.4157 - val_x_pred_binary_loss: 0.1672 - val_x_pred_categorical_loss: 1.5319 - val_x_pred_review_log_lambda_layer_loss: -45.7509 - val_x_pred_coordinates_mdn_layer_loss: -5.1984\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174565/174565 [==============================] - 11s 66us/sample - loss: -106.7232 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9689 - x_pred_review_log_lambda_layer_loss: -108.4129 - x_pred_coordinates_mdn_layer_loss: -3.1339 - val_loss: -45.8126 - val_x_pred_binary_loss: 0.1638 - val_x_pred_categorical_loss: 1.4591 - val_x_pred_review_log_lambda_layer_loss: -45.9771 - val_x_pred_coordinates_mdn_layer_loss: -4.7239\n",
      "Epoch 20/50\n",
      "174565/174565 [==============================] - 11s 61us/sample - loss: -106.7247 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9688 - x_pred_review_log_lambda_layer_loss: -108.3963 - x_pred_coordinates_mdn_layer_loss: -3.1375 - val_loss: -46.3860 - val_x_pred_binary_loss: 0.1589 - val_x_pred_categorical_loss: 1.4458 - val_x_pred_review_log_lambda_layer_loss: -45.5334 - val_x_pred_coordinates_mdn_layer_loss: -4.8681\n",
      "Epoch 21/50\n",
      "174565/174565 [==============================] - 11s 62us/sample - loss: -106.7286 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9684 - x_pred_review_log_lambda_layer_loss: -108.3901 - x_pred_coordinates_mdn_layer_loss: -3.1465 - val_loss: -46.0362 - val_x_pred_binary_loss: 0.1637 - val_x_pred_categorical_loss: 1.5531 - val_x_pred_review_log_lambda_layer_loss: -45.5942 - val_x_pred_coordinates_mdn_layer_loss: -4.9375\n",
      "Epoch 22/50\n",
      "174565/174565 [==============================] - 10s 57us/sample - loss: -106.7063 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9688 - x_pred_review_log_lambda_layer_loss: -108.3540 - x_pred_coordinates_mdn_layer_loss: -3.1508 - val_loss: -46.0406 - val_x_pred_binary_loss: 0.1649 - val_x_pred_categorical_loss: 1.3959 - val_x_pred_review_log_lambda_layer_loss: -42.4430 - val_x_pred_coordinates_mdn_layer_loss: -4.7549\n",
      "Epoch 23/50\n",
      "174565/174565 [==============================] - 10s 55us/sample - loss: -106.6678 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.3133 - x_pred_coordinates_mdn_layer_loss: -3.1524 - val_loss: -45.8843 - val_x_pred_binary_loss: 0.1591 - val_x_pred_categorical_loss: 1.5679 - val_x_pred_review_log_lambda_layer_loss: -45.0646 - val_x_pred_coordinates_mdn_layer_loss: -4.9005\n",
      "Epoch 24/50\n",
      "174565/174565 [==============================] - 9s 52us/sample - loss: -106.7513 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.3862 - x_pred_coordinates_mdn_layer_loss: -3.1560 - val_loss: -46.2122 - val_x_pred_binary_loss: 0.1626 - val_x_pred_categorical_loss: 1.4502 - val_x_pred_review_log_lambda_layer_loss: -45.3149 - val_x_pred_coordinates_mdn_layer_loss: -4.5360\n",
      "Epoch 25/50\n",
      "174565/174565 [==============================] - 9s 50us/sample - loss: -106.7819 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9682 - x_pred_review_log_lambda_layer_loss: -108.4154 - x_pred_coordinates_mdn_layer_loss: -3.1546 - val_loss: -45.9645 - val_x_pred_binary_loss: 0.1730 - val_x_pred_categorical_loss: 1.5985 - val_x_pred_review_log_lambda_layer_loss: -44.2971 - val_x_pred_coordinates_mdn_layer_loss: -4.8282\n",
      "Epoch 26/50\n",
      "174565/174565 [==============================] - 9s 49us/sample - loss: -106.7685 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9687 - x_pred_review_log_lambda_layer_loss: -108.4001 - x_pred_coordinates_mdn_layer_loss: -3.1584 - val_loss: -46.3129 - val_x_pred_binary_loss: 0.1621 - val_x_pred_categorical_loss: 1.4463 - val_x_pred_review_log_lambda_layer_loss: -45.6451 - val_x_pred_coordinates_mdn_layer_loss: -4.9612\n",
      "Epoch 27/50\n",
      "174565/174565 [==============================] - 11s 63us/sample - loss: -106.7485 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9686 - x_pred_review_log_lambda_layer_loss: -108.3748 - x_pred_coordinates_mdn_layer_loss: -3.1577 - val_loss: -46.3817 - val_x_pred_binary_loss: 0.1644 - val_x_pred_categorical_loss: 1.5053 - val_x_pred_review_log_lambda_layer_loss: -45.6705 - val_x_pred_coordinates_mdn_layer_loss: -5.1153\n",
      "Epoch 28/50\n",
      "174565/174565 [==============================] - 10s 58us/sample - loss: -106.6920 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9684 - x_pred_review_log_lambda_layer_loss: -108.2987 - x_pred_coordinates_mdn_layer_loss: -3.1675 - val_loss: -45.8377 - val_x_pred_binary_loss: 0.1682 - val_x_pred_categorical_loss: 1.5967 - val_x_pred_review_log_lambda_layer_loss: -44.3618 - val_x_pred_coordinates_mdn_layer_loss: -4.9867\n",
      "Epoch 29/50\n",
      "174565/174565 [==============================] - 10s 55us/sample - loss: -106.7954 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9684 - x_pred_review_log_lambda_layer_loss: -108.4051 - x_pred_coordinates_mdn_layer_loss: -3.1685 - val_loss: -45.3243 - val_x_pred_binary_loss: 0.1769 - val_x_pred_categorical_loss: 1.5974 - val_x_pred_review_log_lambda_layer_loss: -43.2963 - val_x_pred_coordinates_mdn_layer_loss: -4.7014\n",
      "Epoch 30/50\n",
      "174565/174565 [==============================] - 10s 56us/sample - loss: -106.7060 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9689 - x_pred_review_log_lambda_layer_loss: -108.3218 - x_pred_coordinates_mdn_layer_loss: -3.1675 - val_loss: -46.4714 - val_x_pred_binary_loss: 0.1643 - val_x_pred_categorical_loss: 1.4650 - val_x_pred_review_log_lambda_layer_loss: -45.6958 - val_x_pred_coordinates_mdn_layer_loss: -5.1174\n",
      "Epoch 31/50\n",
      "174565/174565 [==============================] - 10s 55us/sample - loss: -106.7881 - x_pred_binary_loss: 0.4385 - x_pred_categorical_loss: 1.9687 - x_pred_review_log_lambda_layer_loss: -108.3861 - x_pred_coordinates_mdn_layer_loss: -3.1739 - val_loss: -46.3107 - val_x_pred_binary_loss: 0.1714 - val_x_pred_categorical_loss: 1.5265 - val_x_pred_review_log_lambda_layer_loss: -45.6496 - val_x_pred_coordinates_mdn_layer_loss: -5.0978\n",
      "Epoch 32/50\n",
      "174565/174565 [==============================] - 10s 58us/sample - loss: -106.7363 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9686 - x_pred_review_log_lambda_layer_loss: -108.3464 - x_pred_coordinates_mdn_layer_loss: -3.1747 - val_loss: -46.3140 - val_x_pred_binary_loss: 0.1647 - val_x_pred_categorical_loss: 1.5088 - val_x_pred_review_log_lambda_layer_loss: -45.9639 - val_x_pred_coordinates_mdn_layer_loss: -4.9906\n",
      "Epoch 33/50\n",
      "174565/174565 [==============================] - 8s 48us/sample - loss: -106.8451 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9688 - x_pred_review_log_lambda_layer_loss: -108.4241 - x_pred_coordinates_mdn_layer_loss: -3.1761 - val_loss: -45.8914 - val_x_pred_binary_loss: 0.1697 - val_x_pred_categorical_loss: 1.5742 - val_x_pred_review_log_lambda_layer_loss: -45.3536 - val_x_pred_coordinates_mdn_layer_loss: -4.7892\n",
      "Epoch 34/50\n",
      "174565/174565 [==============================] - 9s 50us/sample - loss: -106.8415 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9686 - x_pred_review_log_lambda_layer_loss: -108.4240 - x_pred_coordinates_mdn_layer_loss: -3.1781 - val_loss: -46.3338 - val_x_pred_binary_loss: 0.1694 - val_x_pred_categorical_loss: 1.4942 - val_x_pred_review_log_lambda_layer_loss: -45.9968 - val_x_pred_coordinates_mdn_layer_loss: -5.1159\n",
      "Epoch 35/50\n",
      "174565/174565 [==============================] - 11s 62us/sample - loss: -106.8231 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.3875 - x_pred_coordinates_mdn_layer_loss: -3.1785 - val_loss: -45.5053 - val_x_pred_binary_loss: 0.1710 - val_x_pred_categorical_loss: 1.6274 - val_x_pred_review_log_lambda_layer_loss: -42.7133 - val_x_pred_coordinates_mdn_layer_loss: -4.6666\n",
      "Epoch 36/50\n",
      "174565/174565 [==============================] - 10s 58us/sample - loss: -106.8270 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9687 - x_pred_review_log_lambda_layer_loss: -108.4131 - x_pred_coordinates_mdn_layer_loss: -3.1796 - val_loss: -45.5846 - val_x_pred_binary_loss: 0.1625 - val_x_pred_categorical_loss: 1.3919 - val_x_pred_review_log_lambda_layer_loss: -43.4839 - val_x_pred_coordinates_mdn_layer_loss: -4.9509\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174565/174565 [==============================] - 9s 51us/sample - loss: -106.8027 - x_pred_binary_loss: 0.4384 - x_pred_categorical_loss: 1.9684 - x_pred_review_log_lambda_layer_loss: -108.3869 - x_pred_coordinates_mdn_layer_loss: -3.1813 - val_loss: -45.8910 - val_x_pred_binary_loss: 0.1714 - val_x_pred_categorical_loss: 1.5921 - val_x_pred_review_log_lambda_layer_loss: -44.0058 - val_x_pred_coordinates_mdn_layer_loss: -4.6647\n",
      "Epoch 38/50\n",
      "174565/174565 [==============================] - 11s 61us/sample - loss: -106.8585 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9687 - x_pred_review_log_lambda_layer_loss: -108.4267 - x_pred_coordinates_mdn_layer_loss: -3.1825 - val_loss: -46.2391 - val_x_pred_binary_loss: 0.1692 - val_x_pred_categorical_loss: 1.4902 - val_x_pred_review_log_lambda_layer_loss: -45.9453 - val_x_pred_coordinates_mdn_layer_loss: -5.2102\n",
      "Epoch 39/50\n",
      "174565/174565 [==============================] - 15s 86us/sample - loss: -106.9082 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9683 - x_pred_review_log_lambda_layer_loss: -108.4762 - x_pred_coordinates_mdn_layer_loss: -3.1833 - val_loss: -45.9044 - val_x_pred_binary_loss: 0.1608 - val_x_pred_categorical_loss: 1.3962 - val_x_pred_review_log_lambda_layer_loss: -42.9400 - val_x_pred_coordinates_mdn_layer_loss: -4.9012\n",
      "Epoch 40/50\n",
      "174565/174565 [==============================] - 16s 92us/sample - loss: -106.8864 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9683 - x_pred_review_log_lambda_layer_loss: -108.4648 - x_pred_coordinates_mdn_layer_loss: -3.1845 - val_loss: -47.6843 - val_x_pred_binary_loss: 0.1672 - val_x_pred_categorical_loss: 1.5506 - val_x_pred_review_log_lambda_layer_loss: -44.9585 - val_x_pred_coordinates_mdn_layer_loss: -4.8973\n",
      "Epoch 41/50\n",
      "174565/174565 [==============================] - 10s 59us/sample - loss: -106.8699 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9688 - x_pred_review_log_lambda_layer_loss: -108.4210 - x_pred_coordinates_mdn_layer_loss: -3.1840 - val_loss: -45.7185 - val_x_pred_binary_loss: 0.1695 - val_x_pred_categorical_loss: 1.5203 - val_x_pred_review_log_lambda_layer_loss: -45.7164 - val_x_pred_coordinates_mdn_layer_loss: -4.8063\n",
      "Epoch 42/50\n",
      "174565/174565 [==============================] - 10s 56us/sample - loss: -106.9039 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9684 - x_pred_review_log_lambda_layer_loss: -108.4553 - x_pred_coordinates_mdn_layer_loss: -3.1850 - val_loss: -46.6798 - val_x_pred_binary_loss: 0.1643 - val_x_pred_categorical_loss: 1.4342 - val_x_pred_review_log_lambda_layer_loss: -45.4405 - val_x_pred_coordinates_mdn_layer_loss: -5.0987\n",
      "Epoch 43/50\n",
      "174565/174565 [==============================] - 12s 69us/sample - loss: -106.9008 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9680 - x_pred_review_log_lambda_layer_loss: -108.4458 - x_pred_coordinates_mdn_layer_loss: -3.1870 - val_loss: -46.0835 - val_x_pred_binary_loss: 0.1608 - val_x_pred_categorical_loss: 1.4408 - val_x_pred_review_log_lambda_layer_loss: -45.0088 - val_x_pred_coordinates_mdn_layer_loss: -5.0894\n",
      "Epoch 44/50\n",
      "174565/174565 [==============================] - 11s 63us/sample - loss: -106.8754 - x_pred_binary_loss: 0.4383 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.4135 - x_pred_coordinates_mdn_layer_loss: -3.1862 - val_loss: -46.0542 - val_x_pred_binary_loss: 0.1735 - val_x_pred_categorical_loss: 1.5376 - val_x_pred_review_log_lambda_layer_loss: -45.7146 - val_x_pred_coordinates_mdn_layer_loss: -4.9768\n",
      "Epoch 45/50\n",
      "174565/174565 [==============================] - 12s 71us/sample - loss: -106.9224 - x_pred_binary_loss: 0.4382 - x_pred_categorical_loss: 1.9684 - x_pred_review_log_lambda_layer_loss: -108.4700 - x_pred_coordinates_mdn_layer_loss: -3.1864 - val_loss: -46.0730 - val_x_pred_binary_loss: 0.1753 - val_x_pred_categorical_loss: 1.5638 - val_x_pred_review_log_lambda_layer_loss: -45.2214 - val_x_pred_coordinates_mdn_layer_loss: -4.9515\n",
      "Epoch 46/50\n",
      "174565/174565 [==============================] - 11s 61us/sample - loss: -106.9208 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.4600 - x_pred_coordinates_mdn_layer_loss: -3.1884 - val_loss: -46.0955 - val_x_pred_binary_loss: 0.1652 - val_x_pred_categorical_loss: 1.4374 - val_x_pred_review_log_lambda_layer_loss: -45.3793 - val_x_pred_coordinates_mdn_layer_loss: -4.9652oss: -108.1159 - x_pred_coordinates_mdn_layer_loss\n",
      "Epoch 47/50\n",
      "174565/174565 [==============================] - 9s 54us/sample - loss: -106.8850 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9682 - x_pred_review_log_lambda_layer_loss: -108.4203 - x_pred_coordinates_mdn_layer_loss: -3.1875 - val_loss: -46.5328 - val_x_pred_binary_loss: 0.1717 - val_x_pred_categorical_loss: 1.5911 - val_x_pred_review_log_lambda_layer_loss: -44.1851 - val_x_pred_coordinates_mdn_layer_loss: -4.9016\n",
      "Epoch 48/50\n",
      "174565/174565 [==============================] - 12s 67us/sample - loss: -106.8869 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9681 - x_pred_review_log_lambda_layer_loss: -108.4300 - x_pred_coordinates_mdn_layer_loss: -3.1896 - val_loss: -45.8977 - val_x_pred_binary_loss: 0.1723 - val_x_pred_categorical_loss: 1.5680 - val_x_pred_review_log_lambda_layer_loss: -45.1445 - val_x_pred_coordinates_mdn_layer_loss: -4.9245\n",
      "Epoch 49/50\n",
      "174565/174565 [==============================] - 10s 56us/sample - loss: -106.9602 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9680 - x_pred_review_log_lambda_layer_loss: -108.4961 - x_pred_coordinates_mdn_layer_loss: -3.1916 - val_loss: -46.1049 - val_x_pred_binary_loss: 0.1712 - val_x_pred_categorical_loss: 1.5804 - val_x_pred_review_log_lambda_layer_loss: -45.5834 - val_x_pred_coordinates_mdn_layer_loss: -5.0849\n",
      "Epoch 50/50\n",
      "174565/174565 [==============================] - 11s 65us/sample - loss: -106.9360 - x_pred_binary_loss: 0.4381 - x_pred_categorical_loss: 1.9683 - x_pred_review_log_lambda_layer_loss: -108.4685 - x_pred_coordinates_mdn_layer_loss: -3.1909 - val_loss: -46.0854 - val_x_pred_binary_loss: 0.1737 - val_x_pred_categorical_loss: 1.5286 - val_x_pred_review_log_lambda_layer_loss: -45.8090 - val_x_pred_coordinates_mdn_layer_loss: -4.9173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135578518>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(train_dataset , [train_binary_labels, train_categorical_labels, train_review_labels, train_coordinates_labels], shuffle = True, epochs = epochs, batch_size = batch_size, validation_data=(test_dataset , [test_binary_labels, test_categorical_labels, test_review_labels, test_coordinates_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_input = Input(shape=(latent_dim, ), name = 'decode_input')\n",
    "decode_layer_1 = decode_1(decode_input)\n",
    "decode_layer_2 = decode_2(decode_layer_1)\n",
    "\n",
    "decode_x_pred_coordinates=x_pred_coordinates_mdn_layer(decode_layer_2)\n",
    "# x_pred_coordinates_mu = x_pred_coordinates_mu_layer(decode_layer_2)\n",
    "# x_pred_coordinates_log_var = x_pred_coordinates_log_var_layer(decode_layer_2)\n",
    "# decode_x_pred_coordinates = x_pred_coordinates_layer([x_pred_coordinates_mu, x_pred_coordinates_log_var])\n",
    "\n",
    "decode_x_pred_review = x_pred_review_log_lambda_layer(decode_layer_2)\n",
    "\n",
    "decode_x_pred_binary = x_pred_binary_layer(decode_layer_2) # binary cross entropy\n",
    "decode_x_pred_categorical = x_pred_categorical_layer(decode_layer_2) # categorical cross entropy\n",
    "\n",
    "\n",
    "decoder = Model(decode_input, [decode_x_pred_coordinates, decode_x_pred_review, decode_x_pred_categorical, decode_x_pred_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'InputLayer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8ad28151f4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m SVG(model_to_dot(decoder, show_shapes=True)\n\u001b[0m\u001b[1;32m      2\u001b[0m     .create(prog='dot', format='svg'))\n",
      "\u001b[0;32m~/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mnode_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ib-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minbound_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0minbound_layer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'InputLayer' object is not iterable"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(decoder, show_shapes=True)\n",
    "    .create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Models and Metadata\n",
    "#### Saving Models (Actually, only the decoder matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = vae.to_json()\n",
    "with open(\"./model/vae_full_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "vae.save_weights(\"./model/vae_full_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "encoder = Model(x, [z_mu, z_log_var])\n",
    "model_json = encoder.to_json()\n",
    "with open(\"./model/vae_encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "encoder.save_weights(\"./model/vae_encoder.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model_json = decoder.to_json()\n",
    "with open(\"./model/vae_decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "decoder.save_weights(\"./model/vae_decoder.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating and Saving Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_sample = train_dataset[np.random.choice(len(train_dataset), size=10000, replace=False)]\n",
    "vae_sample_mu, vae_sample_log_var = encoder.predict(vae_sample, batch_size=batch_size)\n",
    "np.save('./model/sample_mu.npy', vae_sample_mu)\n",
    "np.save('./model/sample_log_var.npy', vae_sample_log_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating some Samples for Testing\n",
    "#### Functions for data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "def sample(model, input_mu, input_log_var, samples_per_z=1):\n",
    "    multiplied_input_mu = np.repeat(input_mu, samples_per_z, axis=0)\n",
    "    multiplied_input_log_var = np.repeat(input_log_var, samples_per_z, axis=0)\n",
    "    eps = np.random.normal(size=(multiplied_input_mu.shape[0], latent_dim))\n",
    "    z = reparameterize(multiplied_input_mu, multiplied_input_log_var, eps)\n",
    "    predictions = model.predict(z, batch_size = None, steps = 1)\n",
    "    return reconstruct(predictions)\n",
    "    \n",
    "def reconstruct(predictions):\n",
    "    coordinates, review, categorical, binary = predictions\n",
    "    \n",
    "    # coordinates handled here\n",
    "    print(coordinates.shape)\n",
    "    coordinates_data = np.apply_along_axis(mdn.sample_from_output, 1, coordinates, OUTPUT_DIMS, N_MIXES, temp=1.0)\n",
    "    coordinates_data = np.squeeze(coordinates_data, axis=1)\n",
    "#     mu, log_var = np.split(coordinates, indices_or_sections = 2,axis = 1)\n",
    "#     eps = np.random.normal(size=mu.shape)\n",
    "#     coordinates_data = reparameterize(mu, log_var, eps)\n",
    "    scaler = load(open('./model/standard_scaler.pkl', 'rb'))\n",
    "    coordinates_data = scaler.inverse_transform(coordinates_data)\n",
    "    print(coordinates_data.shape)\n",
    "    \n",
    "    for i, c in enumerate(coordinates_data):\n",
    "        if c[0] > 180.0:\n",
    "            coordinates_data[i][0]= 180.0\n",
    "        if c[0] < -180.0:\n",
    "            coordinates_data[i][0]= -180.0\n",
    "        if c[1] > 180.0:\n",
    "            coordinates_data[i][1]= 180.0\n",
    "        if c[1] < -180.0:\n",
    "            coordinates_data[i][1]= -180.0\n",
    "    \n",
    "    ## review_count handled here\n",
    "    exp_log_review = np.exp(review)\n",
    "    review_data = np.random.poisson(lam=exp_log_review, size = review.shape)\n",
    "    for i, r in enumerate(review_data):\n",
    "        if r[0] < 0:\n",
    "            review_data[i][0] = 0\n",
    "        review_data[i][0] = float(int(review_data[i][0]))\n",
    "    \n",
    "    categorical = np.apply_along_axis(lambda t : np.random.multinomial(1,t), -1, categorical)\n",
    "    categorical = np.apply_along_axis(lambda t : np.argmax(t), -1, categorical)\n",
    "    categorical = np.expand_dims(categorical, axis = -1)\n",
    "    categorical_data = np.apply_along_axis(lambda t : float(reverse_categorical_map[t[0]]), -1, categorical)\n",
    "    categorical_data = np.expand_dims(categorical_data, axis = -1)\n",
    "    binary_data = np.apply_along_axis(lambda t: np.random.binomial(1, t), -1, binary)\n",
    "#     coordinates, reviews = np.split(continuous_data, indices_or_sections=[2], axis = 1)\n",
    "    return np.concatenate([coordinates_data, categorical_data, review_data, binary_data], axis = 1)\n",
    "    \n",
    "\n",
    "def reparameterize(input_mu, input_log_var, eps):\n",
    "    sigma = np.exp(0.5*input_log_var)\n",
    "    return eps*sigma + input_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Samples\n",
    "Make use of the funciton sample to generate samples with our model. U need to supply an array of mu and their respective log var in a separate array to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "vae_samples = sample(decoder, vae_sample_mu, vae_sample_log_var)\n",
    "\n",
    "# Saving the samples in a separate file\n",
    "file_name = './samples/vae_8_sample_' + str(len(vae_samples)) + '.csv'\n",
    "np.savetxt(file_name, vae_samples, delimiter = ',', header='latitude,longitude,stars,review_count,is_open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  36.12722656, -114.97610985,    1.        ,    0.        ,\n",
       "           1.        ],\n",
       "       [  43.64995768,  -79.71934736,    4.        ,    2.        ,\n",
       "           1.        ],\n",
       "       [  41.24716502,  -82.14576402,    3.        ,    3.        ,\n",
       "           1.        ],\n",
       "       [  38.83486706,  -81.44808577,    1.        ,    1.        ,\n",
       "           1.        ],\n",
       "       [  33.52494004, -112.20338825,    5.        ,    6.        ,\n",
       "           1.        ],\n",
       "       [  43.83154703,  -79.53044245,    3.        ,    4.        ,\n",
       "           1.        ],\n",
       "       [  33.47541187, -111.71694681,    5.        ,    3.        ,\n",
       "           1.        ],\n",
       "       [  43.03446893,  -80.8353163 ,    1.5       ,    3.        ,\n",
       "           1.        ],\n",
       "       [  45.55855775,  -73.54997901,    2.        ,    7.        ,\n",
       "           1.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_samples[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
