{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Sample Evaluation\n",
    "\n",
    "This notebook allows you to conduct test on the model by running experiments on the samples generated. You will need\n",
    "\n",
    "1. The actual dataset (full yelp dataset in this case)\n",
    "2. The generated samples\n",
    "\n",
    "Both files need to be in csv format. \n",
    "\n",
    "## Importing Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from prettytable import PrettyTable\n",
    "random.seed(30)\n",
    "np.random.seed(39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_file = '../../datasets/yelp_business.csv'\n",
    "generated_sample_file = './samples/vae_3_sample_10000.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for experiments\n",
    "\n",
    "### Load Samples\n",
    "Loads the datasets for evaluation. \n",
    "1. VAE Generated Samples (Pandas DF)\n",
    "2. Randomly selected Samples from original dataset (Pandas DF)\n",
    "3. Full dataset (Pandas DF)\n",
    "4. Full dataset (NumPy)\n",
    "\n",
    "You are are allowed to specify the number of samples you wish to use for the test. This function will then randomly select that amount of samples from both the original VAE generated dataset and original True dataset for the VAE Generated Samples and Randomly Selected Samples respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(number_of_samples):\n",
    "    generated_sample = np.genfromtxt(generated_sample_file, delimiter = ',', skip_header=1)\n",
    "    real_data = np.genfromtxt(original_dataset_file, delimiter = ',', skip_header=1)\n",
    "    real_sample = real_data[np.random.choice(len(real_data), size=number_of_samples, replace=False)]\n",
    "    generated_sample = generated_sample[np.random.choice(len(generated_sample), size=number_of_samples, replace=False)]\n",
    "\n",
    "    generated = pd.DataFrame(generated_sample, columns = ['latitude','longitude','stars','review_count','is_open'])\n",
    "    real_dataset = pd.DataFrame(real_data, columns = ['latitude','longitude','stars','review_count','is_open'])\n",
    "    real_sample = pd.DataFrame(real_sample, columns = ['latitude','longitude','stars','review_count','is_open'])\n",
    "\n",
    "    return generated, real_sample, real_dataset, real_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Spatial Range Predicates\n",
    "Will generate a list of spatial predicates and return the list. Predicates will be range spatial predicates. Specify actual dataset and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spatial_range_predicates(real_data, number_of_samples=100):\n",
    "\tsample = real_data[np.random.choice(len(real_data), size=number_of_samples, replace=False)]\n",
    "\tpredicates = []\n",
    "\tfor i in sample:\n",
    "\t\tcoordinate = tuple(i[:2])\n",
    "\t\tradius = random.uniform(0, 1)\n",
    "\t\tpredicates.append([('coordinates', 'range',(coordinate, radius))])\n",
    "\treturn predicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Normal Predicates\n",
    "\n",
    "Generating a dict of predicates arranged in a hierarchical order. The ends contain a list of predicates.\n",
    "\n",
    "```python\n",
    "predicate_dict ---- Stars ______________  == (equality)\n",
    "            |           |_______________  >= (more than or equals)\n",
    "            |           |_______________  <= (less than or equals)\n",
    "            | \n",
    "            |  ----- Review_count ______ == (equality)\n",
    "            |           |_______________  >= (more than or equals)\n",
    "            |           |_______________  <= (less than or equals)\n",
    "            |\n",
    "            | ----- is_open _____________ == (equality)\n",
    "```      \n",
    "\n",
    "\n",
    "```python\n",
    "{'stars':{'==':[], '>=':[], '<=':[]}, 'review_count':{'==':[], '>=':[], '<=':[]}, 'is_open':{'==':[], '>=':[], '<=':[]}}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_normal_predicates(real_data, number_of_samples):\n",
    "    ops_dict = {0:'==', 1:'>=', 2:'<='}\n",
    "    predicate_dict = {'stars':{'==':[], '>=':[], '<=':[]}, 'review_count':{'==':[], '>=':[], '<=':[]}, 'is_open':{'==':[], '>=':[], '<=':[]}}\n",
    "    reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "    minimum_review, maximum_review  = int(min(list(real_data[3]))), int(max(list(real_data[3])))\n",
    "\n",
    "    # stars\n",
    "    for _ in range((number_of_samples-2)//2):\n",
    "        ops = random.randint(0, 2)\n",
    "        value = reverse_categorical_map[random.randint(0, 10)]\n",
    "        predicate_dict['stars'][ops_dict[ops]].append([('stars', ops_dict[ops], value)])\n",
    "\n",
    "    # reviews\n",
    "    for _ in range((number_of_samples-2)//2):\n",
    "        ops = random.randint(0, 2)\n",
    "        value = random.randint(minimum_review, maximum_review)\n",
    "        predicate_dict['review_count'][ops_dict[ops]].append([('review_count', ops_dict[ops], value)])\n",
    "\n",
    "    predicate_dict['is_open']['=='].append([('is_open', '==', 1)])\n",
    "    predicate_dict['is_open']['=='].append([('is_open', '==', 0)])\n",
    "    return predicate_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Radius \n",
    "\n",
    "This is to faciliate the spatial range predicates. It true or false depending on whether the target coordinate is within a certain radius of the chosen center. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_radius(coordinate, center, radius):\n",
    "\treturn np.linalg.norm(np.array(coordinate)-np.array(center)) <= radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions\n",
    "The functions below helps us to evaluate the performance of the samples.  \n",
    "\n",
    "- Call **evaluate_dataset** to evaluate the performance of a dataset (in this case, randomly drawn samples/ generated samples) with respect to the actual dataset.\n",
    "- Call **compare_evaluate_dataset** to compare the performance of two datasets with respect to the actual dataset\n",
    "- Call **evaluate_query** to compute the aggregates of dataset for a specific predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation for 1 query\n",
    "def evaluate_query(dataset ,predicates):\n",
    "    dataset.reset_index(drop=True)\n",
    "    for predicate in predicates:\n",
    "        attribute, op, value = predicate\n",
    "        if attribute == 'coordinates':\n",
    "            selection =\tnp.array(np.ones(len(dataset)), dtype='bool')\n",
    "            for index, row in dataset.iterrows():\n",
    "                selection[index] = in_radius((row[0], row[1]), value[0], value[1])\n",
    "            dataset = dataset[selection]\n",
    "            dataset.reset_index(drop=True)\n",
    "        else:\n",
    "            dataset = dataset.query(attribute+op+str(value))\n",
    "            dataset.reset_index(drop=True)\n",
    "    results = dataset.agg(['mean', 'median','count','sum'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_true, y_pred):\n",
    "    if math.isnan(y_pred) or math.isnan(y_true):\n",
    "        return 1\n",
    "    return abs(y_true-y_pred)/(y_true+1)\n",
    "\n",
    "# compute loss for 1 query, returns error dictionary for storing errrors\n",
    "def compute_error(real_results, test_results, error_dict):\n",
    "    for a in error_dict.keys():\n",
    "        for m in error_dict[a].keys():\n",
    "            error_dict[a][m].append(error(real_results[a][m], test_results[a][m]))\n",
    "    return error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating loss for 1 predicate\n",
    "def evaluate_predicate(real_dataset, test_dataset, predicates, error_dict):\n",
    "    real_results = evaluate_query(real_dataset, predicates)\n",
    "    test_results = evaluate_query(test_dataset, predicates)\n",
    "    no_samples = False\n",
    "    \n",
    "    for a in test_results.keys():\n",
    "        if test_results[a]['count'] == 0:\n",
    "            no_samples = True\n",
    "    if no_samples:\n",
    "        print('NO SAMPLES FOR THIS PREDICATE :', predicates)\n",
    "    multiplier = len(real_dataset)/len(test_dataset)\n",
    "    test_results['stars']['count'] = test_results['stars']['count']*multiplier\n",
    "    test_results['stars']['sum'] = test_results['stars']['sum']*multiplier\n",
    "    test_results['review_count']['count'] = test_results['review_count']['count']*multiplier\n",
    "    test_results['review_count']['sum'] = test_results['review_count']['sum']*multiplier\n",
    "    test_results['is_open']['count'] = test_results['is_open']['count']*multiplier\n",
    "    test_results['is_open']['sum'] = test_results['is_open']['sum']*multiplier\n",
    "    \n",
    "    compute_error(real_results, test_results, error_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(real_dataset, test_dataset, predicates_dict):\n",
    "    for a in predicates_dict.keys():\n",
    "        for op in predicates_dict[a].keys():\n",
    "            print(real_dataset.shape, test_dataset.shape)\n",
    "            print('Evaluating Error for ' + str(a) + ' and ' + str(op))\n",
    "            error_dict = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "            error_dict = evaluate_helper(real_dataset, test_dataset, predicates_dict[a][op], error_dict)\n",
    "            error_summary = {'stars':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'review_count':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'is_open':{'sum':'na', 'mean':'na', 'count':'na', 'median':'na'}}\n",
    "            for a2 in error_dict.keys():\n",
    "                for m in error_dict[a2].keys():\n",
    "                    if len(error_dict[a2][m])>0:\n",
    "                        error_summary[a2][m] = sum(error_dict[a2][m])/len(error_dict[a2][m])\n",
    "            display_results(error_summary)\n",
    "            \n",
    "def evaluate_helper(real_dataset, test_dataset, predicates_list, error_dict=None):\n",
    "    if error_dict is None:\n",
    "        error_dict = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "    for predicates in predicates_list:\n",
    "        evaluate_predicate(real_dataset, test_dataset, predicates, error_dict)\n",
    "    return error_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_evaluate_dataset(real_dataset, test_dataset_1, test_dataset_2, predicates_dict):\n",
    "    for a in predicates_dict.keys():\n",
    "        for op in predicates_dict[a].keys():\n",
    "            print(real_dataset.shape, test_dataset_1.shape, test_dataset_2.shape)\n",
    "            print('Evaluating Error for ' + str(a) + ' and ' + str(op))\n",
    "            error_dict_1 = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "            error_dict_2 = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "            error_dict_1 = evaluate_helper(real_dataset, test_dataset_1, predicates_dict[a][op], error_dict_1)\n",
    "            error_dict_2 = evaluate_helper(real_dataset, test_dataset_2, predicates_dict[a][op], error_dict_2)\n",
    "            error_summary_1 = {'stars':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'review_count':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'is_open':{'sum':'na', 'mean':'na', 'count':'na', 'median':'na'}}\n",
    "            error_summary_2 = {'stars':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'review_count':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'is_open':{'sum':'na', 'mean':'na', 'count':'na', 'median':'na'}}\n",
    "            for a2 in error_dict_1.keys():\n",
    "                for m in error_dict_1[a2].keys():\n",
    "                    if len(error_dict_1[a2][m])>0:\n",
    "                        error_summary_1[a2][m] = sum(error_dict_1[a2][m])/len(error_dict_1[a2][m])\n",
    "            for a2 in error_dict_2.keys():\n",
    "                for m in error_dict_2[a2].keys():\n",
    "                    if len(error_dict_2[a2][m])>0:\n",
    "                        error_summary_2[a2][m] = sum(error_dict_2[a2][m])/len(error_dict_2[a2][m])\n",
    "            display_compare_results(error_summary_1, error_summary_2)\n",
    "\n",
    "def display_compare_results(error_summary_1, error_summary_2):\n",
    "    x = PrettyTable()\n",
    "    \n",
    "    column_names = [\"errors\"] + [\"stars\", \"review_count\", \"is_open\"] + [\"next_model\"] + [\"stars\", \"review_count\", \"is_open\"]\n",
    "\n",
    "    x.add_column(column_names[0], [\"mean\", \"median\", \"sum\", \n",
    "        \"count\"])\n",
    "    i = 1\n",
    "    for a in error_summary_1.keys():\n",
    "        x.add_column(column_names[i], [display_helper(error_summary_1[a]['mean']), display_helper(error_summary_1[a]['median']), display_helper(error_summary_1[a]['sum']), display_helper(error_summary_1[a]['count'])])  \n",
    "        i += 1\n",
    "    x.add_column(column_names[i], [\" \", \" \", \" \", \n",
    "        \" \"])\n",
    "    i+= 1\n",
    "    for a in error_summary_2.keys():\n",
    "        x.add_column(column_names[i], [display_helper(error_summary_2[a]['mean']), display_helper(error_summary_2[a]['median']), display_helper(error_summary_2[a]['sum']), display_helper(error_summary_2[a]['count'])])  \n",
    "        i += 1\n",
    "    print(x)\n",
    "\n",
    "def display_helper(number):\n",
    "    if number == 'na':\n",
    "        return number\n",
    "    return_number = number * 100\n",
    "    return_number = round(return_number, 2)\n",
    "    return return_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(error_summary, metric='mean'):\n",
    "    x = PrettyTable()\n",
    "    \n",
    "    column_names = [\"errors\", \"stars\", \"review_count\", \"is_open\"]\n",
    "\n",
    "    x.add_column(column_names[0], [\"mean\", \"median\", \"sum\", \n",
    "        \"count\"])\n",
    "    i = 1\n",
    "    for a in error_summary.keys():\n",
    "        x.add_column(column_names[i],[display_helper(error_summary[a]['mean']), display_helper(error_summary[a]['median']), display_helper(error_summary[a]['sum']), display_helper(error_summary[a]['count'])])  \n",
    "        i += 1\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectivity_filter(lower_percentage, higher_percentage, predicates_list, dataset):\n",
    "    dataset.reset_index(drop=True)\n",
    "    original_size = dataset.size\n",
    "    new_predicates_list = []\n",
    "    for predicates in predicates_list:\n",
    "        new_dataset = dataset\n",
    "        for predicate in predicates:\n",
    "            attribute, op, value = predicate\n",
    "            if attribute == 'coordinates':\n",
    "                selection = np.array(np.ones(len(new_dataset)), dtype='bool')\n",
    "                for index, row in dataset.iterrows():\n",
    "                    selection[index] = in_radius((row[0], row[1]), value[0], value[1])\n",
    "                new_dataset = new_dataset[selection]\n",
    "                new_dataset.reset_index(drop=True)\n",
    "            else:\n",
    "                new_dataset = new_dataset.query(attribute+op+str(value))\n",
    "                new_dataset.reset_index(drop=True)\n",
    "        \n",
    "        count = new_dataset.size\n",
    "        \n",
    "        if count/original_size > lower_percentage and count/original_size <= higher_percentage:\n",
    "            new_predicates_list.append(predicates)\n",
    "\n",
    "    return new_predicates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sample, real_sample, real_dataset, real_data = load_samples(2000)\n",
    "normal_predicates = generate_normal_predicates(real_data, 200)\n",
    "\n",
    "for a in normal_predicates.keys():\n",
    "    for op in normal_predicates[a].keys():\n",
    "        normal_predicates[a][op] = selectivity_filter(0.01, 1, normal_predicates[a][op], real_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "### Evaluating Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.0  |    31.27     |   3.03  |\n",
      "| median |  0.0  |    26.52     |    na   |\n",
      "|  sum   |  7.53 |    30.26     |   8.49  |\n",
      "| count  |  7.53 |     7.53     |   7.53  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.57 |    42.97     |   0.8   |\n",
      "| median |  1.75 |    25.13     |    na   |\n",
      "|  sum   |  1.97 |    45.18     |   2.22  |\n",
      "| count  |  1.27 |     1.27     |   1.27  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.53 |    35.57     |   1.8   |\n",
      "| median |  0.0  |    24.54     |    na   |\n",
      "|  sum   |  5.01 |    33.53     |   5.47  |\n",
      "| count  |  5.04 |     5.04     |   5.04  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  4.41 |     0.0      |   1.73  |\n",
      "| median |  7.22 |     0.0      |    na   |\n",
      "|  sum   | 20.87 |    16.35     |  16.44  |\n",
      "| count  | 16.35 |    16.35     |  16.35  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.83 |     41.1     |   0.45  |\n",
      "| median |  0.29 |    19.15     |    na   |\n",
      "|  sum   |  7.79 |    47.59     |   7.57  |\n",
      "| count  |  6.77 |     6.77     |   6.77  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  1.13 |    21.89     |   1.08  |\n",
      "| median |  0.0  |     5.16     |    na   |\n",
      "|  sum   | 24.37 |     7.53     |  29.26  |\n",
      "| count  | 26.24 |    26.24     |  26.24  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  1.71 |    37.42     |   0.0   |\n",
      "| median |  5.0  |    26.11     |    na   |\n",
      "|  sum   |  1.83 |    40.36     |   0.48  |\n",
      "| count  |  3.03 |     3.03     |   3.03  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(real_dataset, generated_sample, normal_predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.0  |    13.11     |   1.03  |\n",
      "| median |  0.0  |    10.31     |    na   |\n",
      "|  sum   |  5.43 |    15.45     |   6.57  |\n",
      "| count  |  5.43 |     5.43     |   5.43  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.47 |     5.36     |   0.33  |\n",
      "| median |  2.5  |     2.38     |    na   |\n",
      "|  sum   |  1.35 |     4.9      |   0.93  |\n",
      "| count  |  0.78 |     0.78     |   0.78  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.43 |     7.65     |   0.86  |\n",
      "| median |  3.82 |     4.51     |    na   |\n",
      "|  sum   |  3.21 |     6.58     |   4.3   |\n",
      "| count  |  2.72 |     2.72     |   2.72  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  2.56 |     0.0      |   2.2   |\n",
      "| median |  3.7  |     0.0      |    na   |\n",
      "|  sum   | 15.61 |    15.35     |   15.6  |\n",
      "| count  | 15.35 |    15.35     |  15.35  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.62 |     2.86     |   0.58  |\n",
      "| median |  9.98 |     0.33     |    na   |\n",
      "|  sum   |  0.93 |     2.84     |   1.16  |\n",
      "| count  |  0.15 |     0.15     |   0.15  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.96 |     0.37     |   0.1   |\n",
      "| median | 11.11 |     0.0      |    na   |\n",
      "|  sum   |  0.89 |     0.91     |   0.79  |\n",
      "| count  |  0.71 |     0.71     |   0.71  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.51 |     4.99     |   0.0   |\n",
      "| median |  0.0  |    10.56     |    na   |\n",
      "|  sum   |  2.48 |     8.27     |   0.47  |\n",
      "| count  |  2.94 |     2.94     |   2.94  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(real_dataset, real_sample, normal_predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Performance Of Above 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for stars and ==\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.0  |    31.27     |   3.03  |            |  0.0  |    13.11     |   1.03  |\n",
      "| median |  0.0  |    26.52     |    na   |            |  0.0  |    10.31     |    na   |\n",
      "|  sum   |  7.53 |    30.26     |   8.49  |            |  5.43 |    15.45     |   6.57  |\n",
      "| count  |  7.53 |     7.53     |   7.53  |            |  5.43 |     5.43     |   5.43  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for stars and >=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.57 |    42.97     |   0.8   |            |  0.47 |     5.36     |   0.33  |\n",
      "| median |  1.75 |    25.13     |    na   |            |  2.5  |     2.38     |    na   |\n",
      "|  sum   |  1.97 |    45.18     |   2.22  |            |  1.35 |     4.9      |   0.93  |\n",
      "| count  |  1.27 |     1.27     |   1.27  |            |  0.78 |     0.78     |   0.78  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for stars and <=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.53 |    35.57     |   1.8   |            |  0.43 |     7.65     |   0.86  |\n",
      "| median |  0.0  |    24.54     |    na   |            |  3.82 |     4.51     |    na   |\n",
      "|  sum   |  5.01 |    33.53     |   5.47  |            |  3.21 |     6.58     |   4.3   |\n",
      "| count  |  5.04 |     5.04     |   5.04  |            |  2.72 |     2.72     |   2.72  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for review_count and ==\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  4.41 |     0.0      |   1.73  |            |  2.56 |     0.0      |   2.2   |\n",
      "| median |  7.22 |     0.0      |    na   |            |  3.7  |     0.0      |    na   |\n",
      "|  sum   | 20.87 |    16.35     |  16.44  |            | 15.61 |    15.35     |   15.6  |\n",
      "| count  | 16.35 |    16.35     |  16.35  |            | 15.35 |    15.35     |  15.35  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for review_count and >=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.83 |     41.1     |   0.45  |            |  0.62 |     2.86     |   0.58  |\n",
      "| median |  0.29 |    19.15     |    na   |            |  9.98 |     0.33     |    na   |\n",
      "|  sum   |  7.79 |    47.59     |   7.57  |            |  0.93 |     2.84     |   1.16  |\n",
      "| count  |  6.77 |     6.77     |   6.77  |            |  0.15 |     0.15     |   0.15  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for review_count and <=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  1.13 |    21.89     |   1.08  |            |  0.96 |     0.37     |   0.1   |\n",
      "| median |  0.0  |     5.16     |    na   |            | 11.11 |     0.0      |    na   |\n",
      "|  sum   | 24.37 |     7.53     |  29.26  |            |  0.89 |     0.91     |   0.79  |\n",
      "| count  | 26.24 |    26.24     |  26.24  |            |  0.71 |     0.71     |   0.71  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for is_open and ==\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  1.71 |    37.42     |   0.0   |            |  0.51 |     4.99     |   0.0   |\n",
      "| median |  5.0  |    26.11     |    na   |            |  0.0  |    10.56     |    na   |\n",
      "|  sum   |  1.83 |    40.36     |   0.48  |            |  2.48 |     8.27     |   0.47  |\n",
      "| count  |  3.03 |     3.03     |   3.03  |            |  2.94 |     2.94     |   2.94  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for is_open and >=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5) (2000, 5)\n",
      "Evaluating Error for is_open and <=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n"
     ]
    }
   ],
   "source": [
    "compare_evaluate_dataset(real_dataset, generated_sample, real_sample, normal_predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Aggregates For A Single Predicate\n",
    "\n",
    "For the target predicate below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stars', '==', 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_predicates['stars']['=='][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### computes the aggregates by `calling evaluate_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.768078</td>\n",
       "      <td>-97.847361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.163956</td>\n",
       "      <td>-110.633859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1888.403912</td>\n",
       "      <td>-4892.368071</td>\n",
       "      <td>50.0</td>\n",
       "      <td>249.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude    longitude  stars  review_count  is_open\n",
       "mean      37.768078   -97.847361    1.0          4.98     0.76\n",
       "median    36.163956  -110.633859    1.0          4.00     1.00\n",
       "count     50.000000    50.000000   50.0         50.00    50.00\n",
       "sum     1888.403912 -4892.368071   50.0        249.00    38.00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(generated_sample, normal_predicates['stars']['=='][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.868712</td>\n",
       "      <td>-96.615644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.81679</td>\n",
       "      <td>0.891499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.118778</td>\n",
       "      <td>-111.728964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3788.000000</td>\n",
       "      <td>3788.000000</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>3788.00000</td>\n",
       "      <td>3788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>143446.681774</td>\n",
       "      <td>-365980.059602</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>22034.00000</td>\n",
       "      <td>3377.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             latitude      longitude   stars  review_count      is_open\n",
       "mean        37.868712     -96.615644     1.0       5.81679     0.891499\n",
       "median      36.118778    -111.728964     1.0       3.00000     1.000000\n",
       "count     3788.000000    3788.000000  3788.0    3788.00000  3788.000000\n",
       "sum     143446.681774 -365980.059602  3788.0   22034.00000  3377.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_dataset, normal_predicates['stars']['=='][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.310937</td>\n",
       "      <td>-95.224187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.534884</td>\n",
       "      <td>0.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.216772</td>\n",
       "      <td>-82.039882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1647.370307</td>\n",
       "      <td>-4094.640051</td>\n",
       "      <td>43.0</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude    longitude  stars  review_count    is_open\n",
       "mean      38.310937   -95.224187    1.0      4.534884   0.906977\n",
       "median    36.216772   -82.039882    1.0      3.000000   1.000000\n",
       "count     43.000000    43.000000   43.0     43.000000  43.000000\n",
       "sum     1647.370307 -4094.640051   43.0    195.000000  39.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_sample, normal_predicates['stars']['=='][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.241895</td>\n",
       "      <td>-94.062789</td>\n",
       "      <td>3.588</td>\n",
       "      <td>16.127</td>\n",
       "      <td>0.8485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.139621</td>\n",
       "      <td>-109.224904</td>\n",
       "      <td>3.500</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>76483.789967</td>\n",
       "      <td>-188125.578280</td>\n",
       "      <td>7176.000</td>\n",
       "      <td>32254.000</td>\n",
       "      <td>1697.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude      longitude     stars  review_count    is_open\n",
       "mean       38.241895     -94.062789     3.588        16.127     0.8485\n",
       "median     36.139621    -109.224904     3.500         6.000     1.0000\n",
       "count    2000.000000    2000.000000  2000.000      2000.000  2000.0000\n",
       "sum     76483.789967 -188125.578280  7176.000     32254.000  1697.0000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(generated_sample, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.862731e+01</td>\n",
       "      <td>-9.267901e+01</td>\n",
       "      <td>3.632196</td>\n",
       "      <td>3.013706e+01</td>\n",
       "      <td>0.840376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>3.614426e+01</td>\n",
       "      <td>-8.941013e+01</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.745660e+05</td>\n",
       "      <td>1.745660e+05</td>\n",
       "      <td>174567.000000</td>\n",
       "      <td>1.745670e+05</td>\n",
       "      <td>174567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>6.743015e+06</td>\n",
       "      <td>-1.617860e+07</td>\n",
       "      <td>634061.500000</td>\n",
       "      <td>5.260936e+06</td>\n",
       "      <td>146702.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude     longitude          stars  review_count        is_open\n",
       "mean    3.862731e+01 -9.267901e+01       3.632196  3.013706e+01       0.840376\n",
       "median  3.614426e+01 -8.941013e+01       3.500000  8.000000e+00       1.000000\n",
       "count   1.745660e+05  1.745660e+05  174567.000000  1.745670e+05  174567.000000\n",
       "sum     6.743015e+06 -1.617860e+07  634061.500000  5.260936e+06  146702.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_dataset, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.821916</td>\n",
       "      <td>-91.581528</td>\n",
       "      <td>3.66475</td>\n",
       "      <td>29.3185</td>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.157982</td>\n",
       "      <td>-89.305639</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>77643.832785</td>\n",
       "      <td>-183163.055070</td>\n",
       "      <td>7329.50000</td>\n",
       "      <td>58637.0000</td>\n",
       "      <td>1665.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude      longitude       stars  review_count    is_open\n",
       "mean       38.821916     -91.581528     3.66475       29.3185     0.8325\n",
       "median     36.157982     -89.305639     4.00000        8.0000     1.0000\n",
       "count    2000.000000    2000.000000  2000.00000     2000.0000  2000.0000\n",
       "sum     77643.832785 -183163.055070  7329.50000    58637.0000  1665.0000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_sample, [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
