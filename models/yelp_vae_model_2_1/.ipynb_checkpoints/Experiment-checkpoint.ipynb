{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Sample Evaluation\n",
    "\n",
    "This notebook allows you to conduct test on the model by running experiments on the samples generated. You will need\n",
    "\n",
    "1. The actual dataset (full yelp dataset in this case)\n",
    "2. The generated samples\n",
    "\n",
    "Both files need to be in csv format. \n",
    "\n",
    "## Importing Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from prettytable import PrettyTable\n",
    "random.seed(30)\n",
    "np.random.seed(39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_file = '../../datasets/yelp_business.csv'\n",
    "generated_sample_file = './samples/vae_2_1_sample_10000_times_1_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for experiments\n",
    "\n",
    "### Load Samples\n",
    "Loads the datasets for evaluation. \n",
    "1. VAE Generated Samples (Pandas DF)\n",
    "2. Randomly selected Samples from original dataset (Pandas DF)\n",
    "3. Full dataset (Pandas DF)\n",
    "4. Full dataset (NumPy)\n",
    "\n",
    "You are are allowed to specify the number of samples you wish to use for the test. This function will then randomly select that amount of samples from both the original VAE generated dataset and original True dataset for the VAE Generated Samples and Randomly Selected Samples respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(number_of_samples):\n",
    "    generated_sample = np.genfromtxt(generated_sample_file, delimiter = ',', skip_header=1)\n",
    "    real_data = np.genfromtxt(original_dataset_file, delimiter = ',', skip_header=1)\n",
    "    real_sample = real_data[np.random.choice(len(real_data), size=number_of_samples, replace=False)]\n",
    "    generated_sample = generated_sample[np.random.choice(len(generated_sample), size=number_of_samples, replace=False)]\n",
    "\n",
    "    generated = pd.DataFrame(generated_sample, columns = ['latitude','longitude','stars','review_count','is_open'])\n",
    "    real_dataset = pd.DataFrame(real_data, columns = ['latitude','longitude','stars','review_count','is_open'])\n",
    "    real_sample = pd.DataFrame(real_sample, columns = ['latitude','longitude','stars','review_count','is_open'])\n",
    "\n",
    "    return generated, real_sample, real_dataset, real_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Spatial Range Predicates\n",
    "Will generate a list of spatial predicates and return the list. Predicates will be range spatial predicates. Specify actual dataset and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spatial_range_predicates(real_data, number_of_samples=100):\n",
    "\tsample = real_data[np.random.choice(len(real_data), size=number_of_samples, replace=False)]\n",
    "\tpredicates = []\n",
    "\tfor i in sample:\n",
    "\t\tcoordinate = tuple(i[:2])\n",
    "\t\tradius = random.uniform(0, 1)\n",
    "\t\tpredicates.append([('coordinates', 'range',(coordinate, radius))])\n",
    "\treturn predicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Normal Predicates\n",
    "\n",
    "Generating a dict of predicates arranged in a hierarchical order. The ends contain a list of predicates.\n",
    "\n",
    "```python\n",
    "predicate_dict ---- Stars ______________  == (equality)\n",
    "            |           |_______________  >= (more than or equals)\n",
    "            |           |_______________  <= (less than or equals)\n",
    "            | \n",
    "            |  ----- Review_count ______ == (equality)\n",
    "            |           |_______________  >= (more than or equals)\n",
    "            |           |_______________  <= (less than or equals)\n",
    "            |\n",
    "            | ----- is_open _____________ == (equality)\n",
    "```      \n",
    "\n",
    "\n",
    "```python\n",
    "{'stars':{'==':[], '>=':[], '<=':[]}, 'review_count':{'==':[], '>=':[], '<=':[]}, 'is_open':{'==':[], '>=':[], '<=':[]}}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_normal_predicates(real_data, number_of_samples):\n",
    "    ops_dict = {0:'==', 1:'>=', 2:'<='}\n",
    "    predicate_dict = {'stars':{'==':[], '>=':[], '<=':[]}, 'review_count':{'==':[], '>=':[], '<=':[]}, 'is_open':{'==':[], '>=':[], '<=':[]}}\n",
    "    reverse_categorical_map = {0:0, 1:0.5, 2:1, 3:1.5, 4:2, 5:2.5, 6:3, 7:3.5, 8:4, 9:4.5, 10:5}\n",
    "    minimum_review, maximum_review  = int(min(list(real_data[3]))), int(max(list(real_data[3])))\n",
    "\n",
    "    # stars\n",
    "    for _ in range((number_of_samples-2)//2):\n",
    "        ops = random.randint(0, 2)\n",
    "        value = reverse_categorical_map[random.randint(0, 10)]\n",
    "        predicate_dict['stars'][ops_dict[ops]].append([('stars', ops_dict[ops], value)])\n",
    "\n",
    "    # reviews\n",
    "    for _ in range((number_of_samples-2)//2):\n",
    "        ops = random.randint(0, 2)\n",
    "        value = random.randint(minimum_review, maximum_review)\n",
    "        predicate_dict['review_count'][ops_dict[ops]].append([('review_count', ops_dict[ops], value)])\n",
    "\n",
    "    predicate_dict['is_open']['=='].append([('is_open', '==', 1)])\n",
    "    predicate_dict['is_open']['=='].append([('is_open', '==', 0)])\n",
    "    return predicate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_radius(coordinate, center, radius):\n",
    "\treturn np.linalg.norm(np.array(coordinate)-np.array(center)) <= radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation for 1 query\n",
    "def evaluate_query(dataset ,predicates):\n",
    "    dataset.reset_index(drop=True)\n",
    "    for predicate in predicates:\n",
    "        attribute, op, value = predicate\n",
    "        if attribute == 'coordinates':\n",
    "            selection =\tnp.array(np.ones(len(dataset)), dtype='bool')\n",
    "            for index, row in dataset.iterrows():\n",
    "                selection[index] = in_radius((row[0], row[1]), value[0], value[1])\n",
    "            dataset = dataset[selection]\n",
    "            dataset.reset_index(drop=True)\n",
    "        else:\n",
    "            dataset = dataset.query(attribute+op+str(value))\n",
    "            dataset.reset_index(drop=True)\n",
    "    results = dataset.agg(['mean', 'median','count','sum'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_true, y_pred):\n",
    "    if math.isnan(y_pred) or math.isnan(y_true):\n",
    "        return 1\n",
    "    return abs(y_true-y_pred)/(y_true+1)\n",
    "\n",
    "# compute loss for 1 query, returns error dictionary for storing errrors\n",
    "def compute_error(real_results, test_results, error_dict):\n",
    "    for a in error_dict.keys():\n",
    "        for m in error_dict[a].keys():\n",
    "            error_dict[a][m].append(error(real_results[a][m], test_results[a][m]))\n",
    "    return error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating loss for 1 predicate\n",
    "def evaluate_predicate(real_dataset, test_dataset, predicates, error_dict):\n",
    "    real_results = evaluate_query(real_dataset, predicates)\n",
    "    test_results = evaluate_query(test_dataset, predicates)\n",
    "    no_samples = False\n",
    "    \n",
    "    for a in test_results.keys():\n",
    "        if test_results[a]['count'] == 0:\n",
    "            no_samples = True\n",
    "    if no_samples:\n",
    "        print('NO SAMPLES FOR THIS PREDICATE :', predicates)\n",
    "    multiplier = len(real_dataset)/len(test_dataset)\n",
    "    test_results['stars']['count'] = test_results['stars']['count']*multiplier\n",
    "    test_results['stars']['sum'] = test_results['stars']['sum']*multiplier\n",
    "    test_results['review_count']['count'] = test_results['review_count']['count']*multiplier\n",
    "    test_results['review_count']['sum'] = test_results['review_count']['sum']*multiplier\n",
    "    test_results['is_open']['count'] = test_results['is_open']['count']*multiplier\n",
    "    test_results['is_open']['sum'] = test_results['is_open']['sum']*multiplier\n",
    "    \n",
    "    compute_error(real_results, test_results, error_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(real_dataset, test_dataset, predicates_dict):\n",
    "    for a in predicates_dict.keys():\n",
    "        for op in predicates_dict[a].keys():\n",
    "            print(real_dataset.shape, test_dataset.shape)\n",
    "            print('Evaluating Error for ' + str(a) + ' and ' + str(op))\n",
    "            error_dict = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "            error_dict = evaluate_helper(real_dataset, test_dataset, predicates_dict[a][op], error_dict)\n",
    "            error_summary = {'stars':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'review_count':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'is_open':{'sum':'na', 'mean':'na', 'count':'na', 'median':'na'}}\n",
    "            for a2 in error_dict.keys():\n",
    "                for m in error_dict[a2].keys():\n",
    "                    if len(error_dict[a2][m])>0:\n",
    "                        error_summary[a2][m] = sum(error_dict[a2][m])/len(error_dict[a2][m])\n",
    "            display_results(error_summary)\n",
    "            \n",
    "def evaluate_helper(real_dataset, test_dataset, predicates_list, error_dict=None):\n",
    "    if error_dict is None:\n",
    "        error_dict = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "    for predicates in predicates_list:\n",
    "        evaluate_predicate(real_dataset, test_dataset, predicates, error_dict)\n",
    "    return error_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_evaluate_dataset(real_dataset, test_dataset_1, test_dataset_2, predicates_dict):\n",
    "    for a in predicates_dict.keys():\n",
    "        for op in predicates_dict[a].keys():\n",
    "            print(real_dataset.shape, test_dataset_1.shape, test_dataset_2.shape)\n",
    "            print('Evaluating Error for ' + str(a) + ' and ' + str(op))\n",
    "            error_dict_1 = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "            error_dict_2 = {'stars':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'review_count':{'sum':[], 'mean':[], 'median':[], 'count':[]}, 'is_open':{'sum':[], 'mean':[], 'count':[]}}\n",
    "            error_dict_1 = evaluate_helper(real_dataset, test_dataset_1, predicates_dict[a][op], error_dict_1)\n",
    "            error_dict_2 = evaluate_helper(real_dataset, test_dataset_2, predicates_dict[a][op], error_dict_2)\n",
    "            error_summary_1 = {'stars':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'review_count':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'is_open':{'sum':'na', 'mean':'na', 'count':'na', 'median':'na'}}\n",
    "            error_summary_2 = {'stars':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'review_count':{'sum':'na', 'mean':'na', 'median':'na', 'count':'na'}, 'is_open':{'sum':'na', 'mean':'na', 'count':'na', 'median':'na'}}\n",
    "            for a2 in error_dict_1.keys():\n",
    "                for m in error_dict_1[a2].keys():\n",
    "                    if len(error_dict_1[a2][m])>0:\n",
    "                        error_summary_1[a2][m] = sum(error_dict_1[a2][m])/len(error_dict_1[a2][m])\n",
    "            for a2 in error_dict_2.keys():\n",
    "                for m in error_dict_2[a2].keys():\n",
    "                    if len(error_dict_2[a2][m])>0:\n",
    "                        error_summary_2[a2][m] = sum(error_dict_2[a2][m])/len(error_dict_2[a2][m])\n",
    "            display_compare_results(error_summary_1, error_summary_2)\n",
    "\n",
    "def display_compare_results(error_summary_1, error_summary_2):\n",
    "    x = PrettyTable()\n",
    "    \n",
    "    column_names = [\"errors\"] + [\"stars\", \"review_count\", \"is_open\"] + [\"next_model\"] + [\"stars\", \"review_count\", \"is_open\"]\n",
    "\n",
    "    x.add_column(column_names[0], [\"mean\", \"median\", \"sum\", \n",
    "        \"count\"])\n",
    "    i = 1\n",
    "    for a in error_summary_1.keys():\n",
    "        x.add_column(column_names[i], [display_helper(error_summary_1[a]['mean']), display_helper(error_summary_1[a]['median']), display_helper(error_summary_1[a]['sum']), display_helper(error_summary_1[a]['count'])])  \n",
    "        i += 1\n",
    "    x.add_column(column_names[i], [\" \", \" \", \" \", \n",
    "        \" \"])\n",
    "    i+= 1\n",
    "    for a in error_summary_2.keys():\n",
    "        x.add_column(column_names[i], [display_helper(error_summary_2[a]['mean']), display_helper(error_summary_2[a]['median']), display_helper(error_summary_2[a]['sum']), display_helper(error_summary_2[a]['count'])])  \n",
    "        i += 1\n",
    "    print(x)\n",
    "\n",
    "def display_helper(number):\n",
    "    if number == 'na':\n",
    "        return number\n",
    "    return_number = number * 100\n",
    "    return_number = round(return_number, 2)\n",
    "    return return_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(error_summary, metric='mean'):\n",
    "    x = PrettyTable()\n",
    "    \n",
    "    column_names = [\"errors\", \"stars\", \"review_count\", \"is_open\"]\n",
    "\n",
    "    x.add_column(column_names[0], [\"mean\", \"median\", \"sum\", \n",
    "        \"count\"])\n",
    "    i = 1\n",
    "    for a in error_summary.keys():\n",
    "        x.add_column(column_names[i],[display_helper(error_summary[a]['mean']), display_helper(error_summary[a]['median']), display_helper(error_summary[a]['sum']), display_helper(error_summary[a]['count'])])  \n",
    "        i += 1\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectivity_filter(lower_percentage, higher_percentage, predicates_list, dataset):\n",
    "    dataset.reset_index(drop=True)\n",
    "    original_size = dataset.size\n",
    "    new_predicates_list = []\n",
    "    for predicates in predicates_list:\n",
    "        new_dataset = dataset\n",
    "        for predicate in predicates:\n",
    "            attribute, op, value = predicate\n",
    "            if attribute == 'coordinates':\n",
    "                selection = np.array(np.ones(len(new_dataset)), dtype='bool')\n",
    "                for index, row in dataset.iterrows():\n",
    "                    selection[index] = in_radius((row[0], row[1]), value[0], value[1])\n",
    "                new_dataset = new_dataset[selection]\n",
    "                new_dataset.reset_index(drop=True)\n",
    "            else:\n",
    "                new_dataset = new_dataset.query(attribute+op+str(value))\n",
    "                new_dataset.reset_index(drop=True)\n",
    "        \n",
    "        count = new_dataset.size\n",
    "        \n",
    "        if count/original_size > lower_percentage and count/original_size <= higher_percentage:\n",
    "            new_predicates_list.append(predicates)\n",
    "\n",
    "    return new_predicates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sample, real_sample, real_dataset, real_data = load_samples(10000)\n",
    "normal_predicates = generate_normal_predicates(real_data, 200)\n",
    "normal_predicates['coordinates'] = {}\n",
    "normal_predicates['coordinates']['range'] = generate_spatial_range_predicates(real_data, 0)\n",
    "\n",
    "for a in normal_predicates.keys():\n",
    "    if a == 'coordinates':\n",
    "        continue\n",
    "    for op in normal_predicates[a].keys():\n",
    "        normal_predicates[a][op] = selectivity_filter(0.01, 1, normal_predicates[a][op], real_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.0  |    27.01     |   2.35  |\n",
      "| median |  0.0  |    27.49     |    na   |\n",
      "|  sum   |  6.01 |    29.39     |   7.69  |\n",
      "| count  |  6.01 |     6.01     |   6.01  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.33 |    29.52     |   1.27  |\n",
      "| median |  1.75 |    25.75     |    na   |\n",
      "|  sum   |  0.74 |    30.72     |   3.07  |\n",
      "| count  |  0.53 |     0.53     |   0.53  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.31 |    31.21     |   0.82  |\n",
      "| median |  1.04 |    24.54     |    na   |\n",
      "|  sum   |  1.88 |    32.05     |   2.25  |\n",
      "| count  |  1.55 |     1.55     |   1.55  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  3.0  |     0.0      |   1.6   |\n",
      "| median |  5.37 |     0.0      |    na   |\n",
      "|  sum   | 15.44 |    15.65     |  17.03  |\n",
      "| count  | 15.65 |    15.65     |  15.65  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.28 |    27.93     |   0.98  |\n",
      "| median |  0.14 |    19.36     |    na   |\n",
      "|  sum   |  7.25 |    32.66     |   8.86  |\n",
      "| count  |  6.91 |     6.91     |   6.91  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.32 |    20.95     |   0.53  |\n",
      "| median |  0.0  |     6.55     |    na   |\n",
      "|  sum   |  26.5 |     5.47     |  25.54  |\n",
      "| count  | 27.03 |    27.03     |  27.03  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  1.26 |    27.03     |   0.0   |\n",
      "| median |  5.0  |    26.11     |    na   |\n",
      "|  sum   |  8.02 |    24.64     |   1.0   |\n",
      "| count  |  6.29 |     6.29     |   6.29  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(real_dataset, generated_sample, normal_predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.0  |    13.11     |   1.03  |\n",
      "| median |  0.0  |    10.31     |    na   |\n",
      "|  sum   |  5.43 |    15.45     |   6.57  |\n",
      "| count  |  5.43 |     5.43     |   5.43  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.47 |     5.36     |   0.33  |\n",
      "| median |  2.5  |     2.38     |    na   |\n",
      "|  sum   |  1.35 |     4.9      |   0.93  |\n",
      "| count  |  0.78 |     0.78     |   0.78  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for stars and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.43 |     7.65     |   0.86  |\n",
      "| median |  3.82 |     4.51     |    na   |\n",
      "|  sum   |  3.21 |     6.58     |   4.3   |\n",
      "| count  |  2.72 |     2.72     |   2.72  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  2.56 |     0.0      |   2.2   |\n",
      "| median |  3.7  |     0.0      |    na   |\n",
      "|  sum   | 15.61 |    15.35     |   15.6  |\n",
      "| count  | 15.35 |    15.35     |  15.35  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.62 |     2.86     |   0.58  |\n",
      "| median |  9.98 |     0.33     |    na   |\n",
      "|  sum   |  0.93 |     2.84     |   1.16  |\n",
      "| count  |  0.15 |     0.15     |   0.15  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for review_count and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.96 |     0.37     |   0.1   |\n",
      "| median | 11.11 |     0.0      |    na   |\n",
      "|  sum   |  0.89 |     0.91     |   0.79  |\n",
      "| count  |  0.71 |     0.71     |   0.71  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and ==\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |  0.51 |     4.99     |   0.0   |\n",
      "| median |  0.0  |    10.56     |    na   |\n",
      "|  sum   |  2.48 |     8.27     |   0.47  |\n",
      "| count  |  2.94 |     2.94     |   2.94  |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and >=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n",
      "(174567, 5) (2000, 5)\n",
      "Evaluating Error for is_open and <=\n",
      "+--------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(real_dataset, real_sample, normal_predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for stars and ==\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.0  |     7.5      |   1.44  |            |  0.0  |     7.55     |   0.82  |\n",
      "| median |  0.0  |     9.62     |    na   |            |  0.0  |     4.32     |    na   |\n",
      "|  sum   |  1.51 |     8.55     |   3.42  |            |  1.62 |     9.08     |   1.78  |\n",
      "| count  |  1.51 |     1.51     |   1.51  |            |  1.62 |     1.62     |   1.62  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for stars and >=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.06 |     2.15     |   1.17  |            |  0.08 |     2.61     |   0.07  |\n",
      "| median |  0.0  |     6.45     |    na   |            |  0.0  |     0.53     |    na   |\n",
      "|  sum   |  0.44 |     2.08     |   2.23  |            |  0.76 |     3.46     |   0.65  |\n",
      "| count  |  0.39 |     0.39     |   0.39  |            |  0.73 |     0.73     |   0.73  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for stars and <=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.12 |     4.5      |   1.0   |            |  0.12 |     3.92     |   0.46  |\n",
      "| median |  0.0  |     5.46     |    na   |            |  0.0  |     0.76     |    na   |\n",
      "|  sum   |  0.82 |     5.54     |   2.76  |            |  0.74 |     4.51     |   0.88  |\n",
      "| count  |  0.77 |     0.77     |   0.77  |            |  0.59 |     0.59     |   0.59  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for review_count and ==\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  1.01 |     0.0      |   0.16  |            |  0.87 |     0.0      |   0.77  |\n",
      "| median |  0.0  |     0.0      |    na   |            |  0.0  |     0.0      |    na   |\n",
      "|  sum   | 15.16 |    16.24     |  15.95  |            |  0.25 |     0.88     |   0.82  |\n",
      "| count  | 16.24 |    16.24     |  16.24  |            |  0.88 |     0.88     |   0.88  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for review_count and >=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.1  |     1.34     |   0.4   |            |  0.1  |     1.95     |   0.04  |\n",
      "| median |  0.65 |     0.94     |    na   |            |  0.0  |     0.17     |    na   |\n",
      "|  sum   |  0.82 |     0.76     |   1.41  |            |  0.12 |     1.95     |   0.07  |\n",
      "| count  |  0.76 |     0.76     |   0.76  |            |  0.06 |     0.06     |   0.06  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for review_count and <=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  0.08 |     6.94     |   0.51  |            |  0.09 |     0.38     |   0.19  |\n",
      "| median |  0.0  |     5.03     |    na   |            |  0.0  |     0.0      |    na   |\n",
      "|  sum   |  4.04 |     4.67     |   5.11  |            |  0.28 |     0.65     |   0.44  |\n",
      "| count  |  3.94 |     3.94     |   3.94  |            |  0.24 |     0.24     |   0.24  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for is_open and ==\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |  2.14 |     7.14     |   0.0   |            |  0.08 |     7.29     |   0.0   |\n",
      "| median | 10.56 |    10.56     |    na   |            |  0.0  |    10.56     |    na   |\n",
      "|  sum   |  0.17 |     4.36     |   0.45  |            |  0.07 |     7.63     |   0.01  |\n",
      "| count  |  2.8  |     2.8      |   2.8   |            |  0.05 |     0.05     |   0.05  |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for is_open and >=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for is_open and <=\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "| errors | stars | review_count | is_open | next_model | stars | review_count | is_open |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "|  mean  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| median |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "|  sum   |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "| count  |   na  |      na      |    na   |            |   na  |      na      |    na   |\n",
      "+--------+-------+--------------+---------+------------+-------+--------------+---------+\n",
      "(174567, 5) (10000, 5) (10000, 5)\n",
      "Evaluating Error for coordinates and range\n",
      "NO SAMPLES FOR THIS PREDICATE : [('coordinates', 'range', ((36.0102186, -115.1445397), 0.03668927285965928))]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3239eb7ac41e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_evaluate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_predicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-6068a4d85e70>\u001b[0m in \u001b[0;36mcompare_evaluate_dataset\u001b[0;34m(real_dataset, test_dataset_1, test_dataset_2, predicates_dict)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0merror_dict_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_open'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0merror_dict_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_dict_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0merror_dict_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_dict_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0merror_summary_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_open'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0merror_summary_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_open'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'na'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5b39cb97a904>\u001b[0m in \u001b[0;36mevaluate_helper\u001b[0;34m(real_dataset, test_dataset, predicates_list, error_dict)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0merror_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_open'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpredicates\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicates_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mevaluate_predicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d30c9f6a91ef>\u001b[0m in \u001b[0;36mevaluate_predicate\u001b[0;34m(real_dataset, test_dataset, predicates, error_dict)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluating loss for 1 predicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_predicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mno_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c4d9b1a1f263>\u001b[0m in \u001b[0;36mevaluate_query\u001b[0;34m(dataset, predicates)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'coordinates'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_radius\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    303\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/fyp_repo/tf_1/lib/python3.6/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# a 1-element ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 subarr = construct_1d_arraylike_from_scalar(\n\u001b[1;32m    477\u001b[0m                     \u001b[0msubarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_evaluate_dataset(real_dataset, generated_sample, real_sample, normal_predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = evaluate_helper(real_dataset, generated_sample, normal_predicates['stars']['=='])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.009634</td>\n",
       "      <td>-93.650808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.541284</td>\n",
       "      <td>0.798165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>37.726009</td>\n",
       "      <td>-84.773258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>4252.050103</td>\n",
       "      <td>-10207.938077</td>\n",
       "      <td>109.0</td>\n",
       "      <td>931.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude     longitude  stars  review_count     is_open\n",
       "mean      39.009634    -93.650808    1.0      8.541284    0.798165\n",
       "median    37.726009    -84.773258    1.0      4.000000    1.000000\n",
       "count    109.000000    109.000000  109.0    109.000000  109.000000\n",
       "sum     4252.050103 -10207.938077  109.0    931.000000   87.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(generated_sample, normal_predicates['stars']['=='][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.868712</td>\n",
       "      <td>-96.615644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.81679</td>\n",
       "      <td>0.891499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.118778</td>\n",
       "      <td>-111.728964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3788.000000</td>\n",
       "      <td>3788.000000</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>3788.00000</td>\n",
       "      <td>3788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>143446.681774</td>\n",
       "      <td>-365980.059602</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>22034.00000</td>\n",
       "      <td>3377.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             latitude      longitude   stars  review_count      is_open\n",
       "mean        37.868712     -96.615644     1.0       5.81679     0.891499\n",
       "median      36.118778    -111.728964     1.0       3.00000     1.000000\n",
       "count     3788.000000    3788.000000  3788.0    3788.00000  3788.000000\n",
       "sum     143446.681774 -365980.059602  3788.0   22034.00000  3377.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_dataset, normal_predicates['stars']['=='][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.310937</td>\n",
       "      <td>-95.224187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.534884</td>\n",
       "      <td>0.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.216772</td>\n",
       "      <td>-82.039882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1647.370307</td>\n",
       "      <td>-4094.640051</td>\n",
       "      <td>43.0</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude    longitude  stars  review_count    is_open\n",
       "mean      38.310937   -95.224187    1.0      4.534884   0.906977\n",
       "median    36.216772   -82.039882    1.0      3.000000   1.000000\n",
       "count     43.000000    43.000000   43.0     43.000000  43.000000\n",
       "sum     1647.370307 -4094.640051   43.0    195.000000  39.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_sample, normal_predicates['stars']['=='][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stars': {'sum': [0.999991082098204, 0.9998450933312679, 1.511190683557667, 0.02369519829195146, 0.7643239704707807, 0.9999910380613535, 1.3308598816022585, 1.511190683557667, 0.02369519829195146, 1.5566112869481254, 0.02369519829195146, 0.02369519829195146, 1.3308598816022585, 0.999991082098204, 1.5566112869481254, 0.7643239704707807, 0.7643239704707807, 0.9999752297441232, 1.511190683557667, 0.9998450933312679, 0.9999910380613535, 1.3308598816022585, 0.7643239704707807, 0.9998450933312679, 1.3308598816022585, 0.02369519829195146, 0.7643239704707807, 1.3308598816022585, 1.5566112869481254], 'mean': [1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 1, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0], 'median': [1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 1, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0], 'count': [0.9999687880395768, 0.9997676579925651, 1.511190683557667, 0.023694510003267916, 0.7643068551637657, 0.9999596725410332, 1.3308215443114548, 1.511190683557667, 0.023694510003267916, 1.5565277867181635, 0.023694510003267916, 0.023694510003267916, 1.3308215443114548, 0.9999687880395768, 1.5565277867181635, 0.7643068551637657, 0.7643068551637657, 0.9999380766610936, 1.511190683557667, 0.9997676579925651, 0.9999596725410332, 1.3308215443114548, 0.7643068551637657, 0.9997676579925651, 1.3308215443114548, 0.023694510003267916, 0.7643068551637657, 1.3308215443114548, 1.5565277867181635]}, 'review_count': {'sum': [0.999999161719414, 0.9999829290360026, 2.6878574313592014, 0.34087784605638266, 0.10808226072918524, 0.9999989005697247, 0.3438305478558618, 2.6878574313592014, 0.34087784605638266, 1.3068242163491086, 0.34087784605638266, 0.34087784605638266, 0.3438305478558618, 0.999999161719414, 1.3068242163491086, 0.10808226072918524, 0.10808226072918524, 0.9999967937619433, 2.6878574313592014, 0.9999829290360026, 0.9999989005697247, 0.3438305478558618, 0.10808226072918524, 0.9999829290360026, 0.3438305478558618, 0.34087784605638266, 0.10808226072918524, 0.3438305478558618, 1.3068242163491086], 'mean': [1, 1, 0.3996741275308231, 0.32756077129623196, 0.36463990670847946, 1, 0.40890970541672206, 0.3996741275308231, 0.32756077129623196, 0.0911977585240227, 0.32756077129623196, 0.32756077129623196, 0.40890970541672206, 1, 0.0911977585240227, 0.36463990670847946, 0.36463990670847946, 1, 0.3996741275308231, 1, 1, 0.40890970541672206, 0.36463990670847946, 1, 0.40890970541672206, 0.32756077129623196, 0.36463990670847946, 0.40890970541672206, 0.0911977585240227], 'median': [1, 1, 0.25, 0.16666666666666666, 0.46153846153846156, 1, 0.36363636363636365, 0.25, 0.16666666666666666, 0.25, 0.16666666666666666, 0.16666666666666666, 0.36363636363636365, 1, 0.25, 0.46153846153846156, 0.46153846153846156, 1, 0.25, 1, 1, 0.36363636363636365, 0.46153846153846156, 1, 0.36363636363636365, 0.16666666666666666, 0.46153846153846156, 0.36363636363636365, 0.25], 'count': [0.9999687880395768, 0.9997676579925651, 1.511190683557667, 0.023694510003267916, 0.7643068551637657, 0.9999596725410332, 1.3308215443114548, 1.511190683557667, 0.023694510003267916, 1.5565277867181635, 0.023694510003267916, 0.023694510003267916, 1.3308215443114548, 0.9999687880395768, 1.5565277867181635, 0.7643068551637657, 0.7643068551637657, 0.9999380766610936, 1.511190683557667, 0.9997676579925651, 0.9999596725410332, 1.3308215443114548, 0.7643068551637657, 0.9997676579925651, 1.3308215443114548, 0.023694510003267916, 0.7643068551637657, 1.3308215443114548, 1.5565277867181635]}, 'is_open': {'sum': [0.9999614851332614, 0.9997283346916599, 1.2482724985198344, 0.048270808371275564, 0.7877552286167606, 0.9999532775779096, 1.4678703673380276, 1.2482724985198344, 0.048270808371275564, 1.5292827407313678, 0.048270808371275564, 0.048270808371275564, 1.4678703673380276, 0.9999614851332614, 1.5292827407313678, 0.7877552286167606, 0.7877552286167606, 0.999924761116545, 1.2482724985198344, 0.9997283346916599, 0.9999532775779096, 1.4678703673380276, 0.7877552286167606, 0.9997283346916599, 1.4678703673380276, 0.048270808371275564, 0.7877552286167606, 1.4678703673380276, 1.5292827407313678], 'mean': [1, 1, 0.04934409751787809, 0.03347771639189843, 0.00602125976202791, 1, 0.02598378770501284, 0.04934409751787809, 0.03347771639189843, 0.004884713861603902, 0.03347771639189843, 0.03347771639189843, 0.02598378770501284, 1, 0.004884713861603902, 0.00602125976202791, 0.00602125976202791, 1, 0.04934409751787809, 1, 1, 0.02598378770501284, 0.00602125976202791, 1, 0.02598378770501284, 0.03347771639189843, 0.00602125976202791, 0.02598378770501284, 0.004884713861603902], 'count': [0.9999687880395768, 0.9997676579925651, 1.511190683557667, 0.023694510003267916, 0.7643068551637657, 0.9999596725410332, 1.3308215443114548, 1.511190683557667, 0.023694510003267916, 1.5565277867181635, 0.023694510003267916, 0.023694510003267916, 1.3308215443114548, 0.9999687880395768, 1.5565277867181635, 0.7643068551637657, 0.7643068551637657, 0.9999380766610936, 1.511190683557667, 0.9997676579925651, 0.9999596725410332, 1.3308215443114548, 0.7643068551637657, 0.9997676579925651, 1.3308215443114548, 0.023694510003267916, 0.7643068551637657, 1.3308215443114548, 1.5565277867181635]}}\n"
     ]
    }
   ],
   "source": [
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.713536</td>\n",
       "      <td>-92.150396</td>\n",
       "      <td>3.416</td>\n",
       "      <td>18.9825</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.888280</td>\n",
       "      <td>-87.310831</td>\n",
       "      <td>3.500</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>77427.072514</td>\n",
       "      <td>-184300.792823</td>\n",
       "      <td>6832.000</td>\n",
       "      <td>37965.0000</td>\n",
       "      <td>1675.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude      longitude     stars  review_count    is_open\n",
       "mean       38.713536     -92.150396     3.416       18.9825     0.8375\n",
       "median     36.888280     -87.310831     3.500        5.0000     1.0000\n",
       "count    2000.000000    2000.000000  2000.000     2000.0000  2000.0000\n",
       "sum     77427.072514 -184300.792823  6832.000    37965.0000  1675.0000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(generated_sample, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.862731e+01</td>\n",
       "      <td>-9.267901e+01</td>\n",
       "      <td>3.632196</td>\n",
       "      <td>3.013706e+01</td>\n",
       "      <td>0.840376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>3.614426e+01</td>\n",
       "      <td>-8.941013e+01</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.745660e+05</td>\n",
       "      <td>1.745660e+05</td>\n",
       "      <td>174567.000000</td>\n",
       "      <td>1.745670e+05</td>\n",
       "      <td>174567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>6.743015e+06</td>\n",
       "      <td>-1.617860e+07</td>\n",
       "      <td>634061.500000</td>\n",
       "      <td>5.260936e+06</td>\n",
       "      <td>146702.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude     longitude          stars  review_count        is_open\n",
       "mean    3.862731e+01 -9.267901e+01       3.632196  3.013706e+01       0.840376\n",
       "median  3.614426e+01 -8.941013e+01       3.500000  8.000000e+00       1.000000\n",
       "count   1.745660e+05  1.745660e+05  174567.000000  1.745670e+05  174567.000000\n",
       "sum     6.743015e+06 -1.617860e+07  634061.500000  5.260936e+06  146702.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_dataset, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.821916</td>\n",
       "      <td>-91.581528</td>\n",
       "      <td>3.66475</td>\n",
       "      <td>29.3185</td>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>36.157982</td>\n",
       "      <td>-89.305639</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>77643.832785</td>\n",
       "      <td>-183163.055070</td>\n",
       "      <td>7329.50000</td>\n",
       "      <td>58637.0000</td>\n",
       "      <td>1665.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude      longitude       stars  review_count    is_open\n",
       "mean       38.821916     -91.581528     3.66475       29.3185     0.8325\n",
       "median     36.157982     -89.305639     4.00000        8.0000     1.0000\n",
       "count    2000.000000    2000.000000  2000.00000     2000.0000  2000.0000\n",
       "sum     77643.832785 -183163.055070  7329.50000    58637.0000  1665.0000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_query(real_sample, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639744.41325"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
